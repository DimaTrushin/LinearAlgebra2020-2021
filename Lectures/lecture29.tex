\ProvidesFile{lecture29.tex}[Лекция 29]


\subsection{Метод наименьших квадратов}

Пусть мы хотим решить систему $Ax = b$, где $A\in \MatrixDim{m}{n}$, $b\in \mathbb R^m$ и $x\in \mathbb R^n$ -- столбец неизвестных.
И предположим, что система не имеет решений, но от этого наше желание ее решить не становится слабее.
Давайте обсудим, как удовлетворить наши желания в подобной ситуации и когда такие ситуации обычно встречаются.

Введем на пространстве $\mathbb R^m$ стандартное скалярное произведение $(x,y) = x^t y$.
Тогда, на процесс решения системы можно смотреть так: мы подбираем $x\in \mathbb R^n$ так, чтоб $\rho(Ax, b) = 0$.
Если решить систему невозможно, то этот подход подсказывает, как надо поступить.
Надо пытаться минимизировать расстояние между $Ax$ и $b$.
То есть решить задачу
\[
\begin{aligned}
&\rho(Ax, b)\to \min\\
&x\in \mathbb R^n
\end{aligned}
\]
Теперь давайте поймем, как надо решать такую задачу.
Пусть матрица $A$ имеет вид $A = (A_1|\ldots|A_n)$, где $A_i\in \mathbb R^m$ -- ее столбцы.
Тогда система $Ax = b$ означает, $x_1A_1 + \ldots + x_n A_n = b$.
То есть система разрешима тогда и только тогда, когда $b\in \langle A_1,\ldots, A_n\rangle$.
Значит наша задача минимизировать расстояние между $b$ и $\langle A_1,\ldots,A_n\rangle$.
Тогда утверждение~\ref{claim::DistAngle} подсказывает, что минимум расстояния достигается на $b_0 = \pr_{\langle A\rangle}b$.
В этом случае вместо исходной системы $Ax = b$ мы должны решить систему $Ax = b_0$.
И если $x_0$ -- ее решение, то $\rho(Ax_0, b)$ как раз и будет минимальным.

Давайте теперь предположим, что столбцы матрицы $A$ линейно независимы.
Тогда по формуле <<Атата>> мы знаем, что $b_0 = A(A^tA)^{-1}A^tb$.
Кроме этого должно выполняться $b_0 = Ax_0$.
Так как столбцы $A$ линейно независимы, такое $x_0$ должно быть единственным.
Но мы видим, что в качестве $x_0$ подходит $x_0 = (A^tA)^{-1}A^tb$.

\subsection{Матрица Грама}
\label{subsection::Gram}

Прежде чем переходить к объемам, мне понадобятся некоторые технические вещи.

\begin{definition}
Пусть $V$ -- евклидово пространство и $v_1,\ldots,v_k\in V$ -- произвольный набор векторов ($k$ НЕ обязательно равно размерности пространства).
Тогда матрица
\[
G(v_1,\ldots,v_k) =
\begin{pmatrix}
{(v_1,v_1)}&{\ldots}&{(v_1,v_k)}\\
{\vdots}&{\ddots}&{\vdots}\\
{(v_k,v_1)}&{\ldots}&{(v_k,v_k)}\\
\end{pmatrix}
\in\Matrix{k}
\]
называется матрицей Грама системы векторов $v_1,\ldots,v_k$.%
\footnote{Обратите внимание, тут важен порядок векторов.
То есть формально матрица Грама зависит от набора $(v_1,\ldots,v_k)\in V^k$.}
\end{definition}

Если $e_1,\ldots,e_n$ -- некоторый базис пространства $V$, то $B = G(e_1,\ldots,e_n)$ -- матрица скалярного произведения заданная в базисе $e_1,\ldots,e_n$.
Таким образом матрица Грама -- это некоторое обобщение матрицы билинейной формы.

Теперь вспомним, что у любой билинейной формы есть операторная запись.
Давайте введем следующее обозначение: для произвольных векторов $w, u\in V$ положим $w\cdot u = (w, u)$.
Тогда для набора $v = (v_1,\ldots,v_k)$ выполнено
\[
G(v_1,\ldots,v_k) = 
\begin{pmatrix}
{v_1}\\{\vdots}\\{v_k}
\end{pmatrix}
\cdot
\begin{pmatrix}
{v_1}&{\ldots}&{v_k}
\end{pmatrix}
=
v^t \cdot v
\]

Пусть теперь $C\in \MatrixDim{k}{r}$ -- некоторая матрица.
Тогда из набора $(v_1,\ldots,v_k)$ можно построить новый набор $(u_1,\ldots,u_r) = (v_1,\ldots,v_k)C$ или кратко $u = vC$.
Тогда 
\[
G(u) = G(vC) = (vC)^t \cdot vC = C^t v^t \cdot v C = C^t G(v) C
\]
То есть $G((v_1,\ldots,v_k)C) = C^t G(v_1,\ldots,v_k)C$.


\begin{claim}
\label{claim::GramMatrixFull}
Пусть $v_1,\ldots,v_k\in V$ -- произвольный набор векторов в евклидовом пространстве.
Тогда
\begin{enumerate}
\item Пусть $\alpha_1,\ldots,\alpha_k \in \mathbb R$, введем обозначение $\alpha = (\alpha_1,\ldots,\alpha_k)^t$.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item $\alpha_1 v_1 + \ldots + \alpha_k v_k = 0$.

\item $G(v_1,\ldots,v_k)\alpha= 0$.

\item $\alpha^tG(v_1,\ldots,v_k)\alpha= 0$.
\end{enumerate}
\item $\rk G(v_1,\ldots,v_k) = \dim \langle v_1,\ldots,v_k\rangle$.

\item  $\det G(v_1,\ldots,v_k)\geqslant 0$.
При этом равенство достигается тогда и только тогда, когда векторы линейно зависимы.

\item Если $C\in\Matrix{k}$ является матрицей элементарного преобразования I или II типа, то 
\[
\det G(v_1,\ldots,v_k) = \det G((v_1,\ldots,v_k)C)
\]
\end{enumerate}
\end{claim}
\begin{proof}
1) Пусть $v = (v_1,\ldots,v_k)$.
Тогда условие $v\alpha = 0$ влечет, что $v^t \cdot v\alpha = 0$.
Но это означает, что $G(v_1,\ldots,v_k) \alpha = 0$.
Домножая слева на $\alpha^t$ получаем, что $\alpha^t G(v_1,\ldots,v_k) \alpha = 0$.
Осталось показать из последнего в первое.
Для этого заметим, что $0 = \alpha^t G(v_1,\ldots,v_k) \alpha = \alpha^t v^t \cdot v\alpha = (v\alpha, v\alpha)$.
А значит $v\alpha = 0$.

2) Пункт~(1) эквивалентность (a) и (b) означает, что векторы $v_1,\ldots,v_k$ обладают теми же линейными зависимостями, что и столбцы матрицы $G(v_1,\ldots,v_k)$.
В частности столбцовый ранг $G(v_1,\ldots,v_k)$ равен рангу системы векторов $(v_1,\ldots,v_k)$.
А последняя совпадает с размерностью линейной оболочки $\langle v_1,\ldots,v_k\rangle$.

3) Давайте на пространстве $\mathbb R^k$ рассмотрим билинейную форму $\beta(x,y) = x^t G(v_1,\ldots,v_k)y$.
Давайте покажем, что она не отрицательно определена.
Тогда, ее определитель должен быть не отрицательным.
Действительно, тогда в каком-то базисе ее матрица диагональна с $1$ и $0$ на диагонали, а значит в этом базисе определитель будет неотрицательным.
Но определитель билинейной формы не меняет знак при замене базиса (раздел~\ref{subsection::BilChar}).
Теперь остается лишь проверить, что $\beta(x,x)\geqslant 0$ для любого $x\in \mathbb R^k$.
Действительно
\[
x^t G(v_1,\ldots,v_k) x = x^t v^t\cdot v x = (vx, vx) \geqslant 0
\]
Последнее неравенство выполнено для любого вектора $vx\in V$ по определению скалярного произведения.

4) Если $C$ -- матрица элементарного преобразования, то $G((v_1,\ldots,v_k)C) = C^t G(v_1,\ldots,v_k)C$.
А значит $\det(G((v_1,\ldots,v_k)C)) = \det(G(v_1,\ldots,v_k))\det C^2$.
Но для элементарных преобразований I и II типов $\det C = \pm 1$.
\end{proof}

Заметим, что из третьего пункта следует вот какое наблюдение.
Если $v_1,\ldots, v_k$ -- линейно независимый набор векторов, из которого процессом ортогонализации Грама-Шмидта мы получили набор $u_1,\ldots,u_k$, то $\det G(u_1,\ldots,u_k) = \det G(v_1,\ldots,v_k)$.

\subsection{Объемы}

Теперь самое время прикоснуться к объемам.
Надо сказать, что существует общая теория вычисления объемов в евклидовом пространстве $V$.
Она позволяет посчитать <<объем>> любого подмножества в $V$.
Данная конструкция ведет к понятию меры Лебега и далее к интегралу Лебега.
Мы, конечно же, не будем развивать подобную теорию в такой общности, а всего лишь ограничимся вычислением объемов для простых и естественных с точки зрения линейной алгебры фигур -- многомерных параллелепипедов.

\begin{definition}
Пусть $V$ -- евклидово пространство и $v_1,\ldots,v_k\in V$ -- набор векторов, тогда $k$-мерным параллелепипедом натянутым на $v_1,\ldots,v_k$ называется следующее множество
\[
\Pi(v_1,\ldots,v_k) = \Bigl\{\sum_{i=1}^k x_i v_i\mid 0\leqslant x_i \leqslant 1\Bigl\}
\]
\end{definition}

\paragraph{VIP пример}

Я хочу разобрать один важный пример.
Пусть $V = \mathbb R^2$ -- плоскость со стандартным скалярным произведением $(x, y) = x^t y$ и $v_1,v_2\in V$ -- два ортогональных вектора.
Если я заменю $v_2$ на $v_2 + \lambda v_1$, то геометрически я наклоню мой параллелепипед вдоль направления $v_1$ как на рисунке ниже:
\[
\begin{aligned}
\xymatrix{
	{}\ar@{-}[rr]&{}&{}\\
	{}\ar[u]^{v_2}\ar[rr]^{v_1}&{}&{}\ar@{-}[u]\\
}
\end{aligned}
\quad\longrightarrow\quad
\begin{aligned}
\xymatrix{
	{}\ar@{--}[r]&{}\ar@{-}[rr]&{}&{}\\
	{}\ar@{--}[u]\ar[rr]^{v_1}\ar[ru]|{v_2 + \lambda v_1}&{}&{}\ar@{--}[u]\ar@{-}[ru]&{}\\
}
\end{aligned}
\]
На рисунке мы видим, что параллелепипед справа отличается от параллелепипеда слева перестановкой треугольника отмеченного пунктиром.
А значит их площади одинаковые.
Давайте посмотрим на матрицы Грама двух наборов векторов:
\[
G(v_1, v_2 + \lambda v_1) = 
\begin{pmatrix}
{1}&{0}\\
{\lambda}&{1}
\end{pmatrix}
G(v_1,v_2)
\begin{pmatrix}
{1}&{\lambda}\\
{0}&{1}
\end{pmatrix}
\quad\text{при этом}\quad
G(v_1,v_2) =
\begin{pmatrix}
{|v_1|^2}&{0}\\
{0}&{|v_2^2|}
\end{pmatrix}
\]
То есть $\det G(v_1,v_2 + \lambda v_1) = \det G(v_1,v_2) = |v_1|^2 |v_2|^2 = S_{\Pi(v_1,v_2)}^2$.
То есть определитель матрицы Грамма дает нам квадрат площади параллелограмма, натянутого на векторы $v_1$, $v_2$.
Этот пример подсказывает, как надо определять объемы в общем случае.

\begin{definition}
Пусть $v_1,\ldots, v_k\in V$ -- произвольный набор векторов в евклидовом пространстве.
Тогда определим $k$-мерный объем параллелепипеда $\Pi(v_1,\ldots,v_k)$ по следующей формуле:
\[
\Vol_k(\Pi(v_1,\ldots,v_k)) = \sqrt{\det G(v_1,\ldots,v_k)}
\]
\end{definition}

Давайте теперь покажем, что объем $k$-мерного параллелепипеда можно считать через площадь ($k-1$-мерный объем) основания на высоту.

\begin{claim}
Пусть $v_1,\ldots,v_k\in V$ -- произвольный набор векторов в евклидовом пространстве.
Тогда
\[
\Vol_k(\Pi(v_1,\ldots,v_k)) = \Vol_{k-1}(\Pi(v_1,\ldots,v_{k-1}))\rho(v_k, \langle v_1,\ldots,v_{k-1}\rangle)
\] 
\end{claim}
\begin{proof}
Пусть $h = \ort_{\langle v_1,\ldots,v_{k-1}\rangle} v_k$.
Тогда мы знаем, что $h = v_k - \sum_{i=1}^{k-1}\alpha_i v_i$ для каких-то коэффициентов $\alpha_i$ (например это следует из алгоритма Грама-Шмидта).
Значит по утверждению~\ref{claim::GramMatrixFull} пункт~(4),
\[
\det G(v_1,\ldots,v_{k-1}, h) = \det G(v_1,\ldots,v_{k-1},v_k)
\]
Так как $h \bot v_i$, то 
\[
G(v_1,\ldots,v_{k-1}, h) = 
\begin{pmatrix}
{G(v_1,\ldots,v_{k-1})}&{0}\\
{0}&{(h, h)}
\end{pmatrix}
\]
То есть 
\[
\det G(v_1,\ldots,v_{k-1}, h) = \det G(v_1,\ldots, v_{k-1}) (h, h)
\]
\end{proof}


Последняя формула позволяет нам вычислять расстояние от вектора до подпространства с помощью объемов.
А именно, если $v\in V$ и $L\subseteq V$ -- подпространство с базисом $e_1,\ldots,e_k$, то 
\[
\rho(v, L) = \sqrt{\frac{\det G(e_1,\ldots,e_k, v)}{\det G(e_1,\ldots,e_k)}}
\]

\begin{claim}
Пусть $V$ -- евклидово пространство размерности $n$, $v_1,\ldots,v_n\in V$ -- некоторый набор векторов и $\varphi\colon V\to V$ -- линейный оператор.
Тогда 
\[
\Vol_n(\varphi(\Pi(v_1,\ldots,v_n))) = |\det \varphi| \Vol_n(\Pi(v_1,\ldots,v_n))
\]
\end{claim}
\begin{proof}
Давайте выберем произвольный ортонормированный базис $e_1,\ldots,e_n\in V$.
Тогда $V$ превращается в $\mathbb R^n$, скалярное произведение становится стандартным $(x, y) = x^t y$, линейное отображение превращается в умножение на матрицу $\varphi(x) = Cx$, а векторы $v_1,\ldots,v_n$ расставим по столбцам матрицы $A = (v_1|\ldots|v_n)$.%
\footnote{Заметьте, что мы избрали мучительный и болезненный путь расчета в координатах.
У вас может появиться соблазн найти другое доказательство.
Однако, увы и ах.
Так как в формулировке присутствует определитель отображения, то у нас нет другого способа, потому что невозможно определить $\det \varphi$ без базиса.
Его свойствами пользоваться можно без базиса, но посчитать нет.}

Заметим, что $G(v_1,\ldots,v_n) = A^t A$.
Кроме того, $\varphi(\Pi(v_1,\ldots,v_n)) = \Pi(\varphi(v_1),\ldots,\varphi(v_n))$.
Значит
\[
\Vol_n(\varphi(\Pi(v_1,\ldots,v_n))) =\sqrt{\det G(\varphi(v_1),\ldots,\varphi(v_n))} = \sqrt{\det ((CA)^tCA)} = |\det C| |\det A|
\]
При этом 
\[
\Vol_n(\Pi(v_1,\ldots,v_n)) = \sqrt{\det(A^tA)} = |\det A|
\]
А так как $\det C = \det \varphi$ по определению, то все доказано.
\end{proof}

\begin{claim}
\label{claim::Volume}
Пусть $v_1,\ldots,v_k\in V$ -- набор векторов в евклидовом пространстве и $C\in \Matrix{k}$ -- произвольная матрица.
Тогда
\[
\Vol_k\Pi((v_1,\ldots,v_k)C) = |\det C| \Vol_k\Pi(v_1,\ldots,v_k)
\]
\end{claim}
\begin{proof}
По формуле для замены матрицы Грама (раздел~\ref{subsection::Gram}) мы знаем, что
\[
G((v_1,\ldots,v_k)C) = C^t G(v_1,\ldots,v_k) C
\]
Значит $\det G((v_1,\ldots,v_k)C) = \det C^2 \det G(v_1,\ldots,v_k)$.
Откуда следует требуемое по определению объемов.
\end{proof}

Таким образом, при линейной замене образующих параллелепипеда мы получаем другой параллелепипед, объем которого меняется на модуль определителя матрицы замены.
Мы хотим избавиться от модуля в этой формуле, чтобы объем мог быть положительным и отрицательным.

\subsection{Ориентированный объем}

\paragraph{Конструкция ориентированного объема}

Пусть $V$ -- евклидово пространство размерности $n$.
Рассмотрим все возможные наборы из $n$ векторов -- $V^n$.
Множество $V^n$ разбивается на две части: когда набор $(v_1,\ldots,v_n)$ линейно зависим и когда он линейно независим.
В первом случае $\Vol_n\Pi(v_1,\ldots,v_n) = 0$, а во втором $\Vol_n\Pi(v_1,\ldots,v_n)\neq 0$.
Мы хотим поделить все линейно независимые наборы (то есть базисы) на два класса: для одного класса объемы будут положительные, а для другого -- отрицательные.

\begin{definition}
Пусть $(v_1,\ldots,v_n)$ и $(u_1,\ldots,u_n)$ -- два базиса пространства $V$.
Тогда существует единственная матрица $C\in \Matrix{n}$ такая, что $(v_1,\ldots,v_n) = (u_1,\ldots,u_n)C$.%
\footnote{Потому что любой вектор однозначно раскладывается по базису.}
Будем говорить, что $(v_1,\ldots,v_n)$ эквивалентно $(u_1,\ldots,u_n)$ и писать $(v_1,\ldots,v_n)\sim(u_1,\ldots,u_n)$, если $\det C > 0$.
\end{definition}

\begin{claim}
Пусть $V$ -- евклидово пространство размерности $n$.
Тогда
\begin{enumerate}
\item Отношение, введенное на базисах, является отношением эквивалентности на множестве всех упорядоченных базисов
\[
G_n(V) = \{(v_1,\ldots,v_n)\mid v_i\in V,\;v_i\text{ линейно независимы }\}
\]

\item Множество упорядоченных базисов $G_n(V)$ разбивается на два класса эквивалентности.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Если $v \in G_n(V)$ -- некоторый набор, то $v = v E$, а $\det E = 1 > 0$.
Значит $v \sim v$.
Если $v = u C$, то $u = vC^{-1}$.
Но знак у $\det C$ такой же как и у $\det C^{-1}$.
Значит если $v \sim u$, то $u\sim v$.
Теперь пусть $v\sim u$ и $u\sim w$, то есть $v=  u C$ и $u = w D$.
В этом случае $v = wDC$, то $\det (DC) =\det D \det C >0$, то есть $v\sim w$.

(2) Пусть $v,u, w\in G_n(V))$, и пусть $v\not\sim u$ и $v\not\sim w$.
Покажем, что в этом случае $u \sim w$.
Действительно $v\not\sim u$ означает, $v = u C$ и $\det C < 0$.
Аналогично, $v = w D$ и $\det D < 0$.
Тогда $u = w DC^{-1}$ и $\det(DC^{-1}) > 0$, то есть $u\sim w$.
Таким образом классов эквивалентности не более двух.
С другой стороны.
Если набор $v$ лежит в одном классе, а $C$ -- произвольная обратимая матрица с отрицательным определителем, то набор $v C$ лежит в другом классе.
Значит их в точности два.
\end{proof}

Таким образом все базисы у нас поделились на две группы.
Какую-то из этих групп нам надо назвать положительной, другую отрицательной.
Какую выбрать -- это наша свобода.
После подобного выбора все наборы в $V^n$ делятся на три группы: (1) линейно зависимые, у них объем ноль, (2) положительные, натянутые на них параллелепипеды имеют положительный объем, (3) отрицательные, натянутые на них параллелепипеды имеют отрицательный объем.
Положительные базисы будем еще называть положительно ориентированными, а отрицательные -- отрицательно ориентированными.
Если зафиксированы положительные и отрицательные базисы, будем говорить, что на $V$ зафиксирована ориентация.
% TO DO
% Может быть это стоит разбить в определения!
