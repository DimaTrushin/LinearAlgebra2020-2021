\ProvidesFile{lecture17.tex}[Лекция 17]


\paragraph{Собственные и корневые подпространства}

\begin{definition}
Пусть $V$ -- некоторое векторное пространство над полем $F$ и $\varphi \colon V\to V$ -- линейный оператор.
Для любого числа $\lambda \in F$ определим собственное подпространство
\[
V_\lambda = \{v\in V\mid \varphi v = \lambda v\}
\]
\end{definition}

Заметим, что такое подмножество обязательно является подпространством, например, потому что совпадает с $\ker (\varphi - \lambda \Identity)$.
Действительно, $\varphi v = \lambda v$ тогда и только тогда, когда $\varphi v - \lambda v = 0$.
Что равносильно тому, что $(\varphi - \lambda \Identity)v = 0$, что значит $v\in \ker(\varphi - \lambda \Identity)$.

\paragraph{Замечание}

Обратите внимание, что оператор $\varphi$ на собственном подпространстве $V_\lambda$ действует как скалярный оператор $\lambda \Identity$, то есть все умножает на $\lambda$ просто по определению $\varphi v = \lambda v$ для любого $v\in V_\lambda$.
Тут Капитан Очевидность передает привет.
Однако, не спешите, его помощник по имени Нетривиальное Следствие сейчас расскажет пару слов.

Давайте рассмотрим произвольный многочлен $f\in F[x]$, тогда определен оператор $f(\varphi)\colon V\to V$.
Так вот, оператор $f(\varphi)$ на собственном подпространстве $V_\lambda$ действует умножением на $f(\lambda)$, то есть $f(\varphi) v = f(\lambda) v$.
Это очень простое наблюдение жутко полезно.


\begin{claim}
\label{claim::EigenSpec}
Пусть $V$ -- некоторое векторное пространство над полем $F$ и $\varphi \colon V\to V$ -- линейный оператор.
Тогда следующие условия равносильны:
\begin{enumerate}
\item $V_\lambda \neq 0$.

\item $\lambda \in \spec_F\varphi$.

\item $\lambda$ -- корень $\chi_\varphi(t)$.

\item $\lambda$ -- корень минимального многочлена для $\varphi$.
\end{enumerate}
\end{claim}
\begin{proof}
Эквивалентность последних трех условий была доказана в утверждениях~\ref{claim::MinPoly} и~\ref{claim::CharSpec}.
Здесь эти условия приводятся, чтобы создать общую картину у читающего.
Давайте проверим эквивалентность первого условия с оставшимися.

(1)$\Rightarrow$ Пусть $V_\lambda \neq 0$, тогда $\varphi v = \lambda v$ для некоторого ненулевого вектора.
Значит $(\varphi - \lambda \Identity)v = 0$.
А значит оператор $\varphi - \lambda \Identity$ не обратим.

$\Rightarrow$(1) Пусть $\varphi -\lambda \Identity$ не обратим.
Тогда по одному из эквивалентных свойств обратимости оператора (утверждение~\ref{claim::OperatorInvert}), это означает, что $\varphi - \lambda \Identity$ имеет не нулевое ядро.
То есть есть ненулевой вектор $v\in V$ такой, что $(\varphi - \lambda \Identity)v = 0$.
А это и значит, что $\varphi v = \lambda v$ после раскрытия скобок и переноса второго слагаемого в право.
\end{proof}

\begin{definition}
Пусть $V$ -- векторное пространство над полем $F$, $\varphi\colon V\to V$ -- линейный оператор и $\lambda$ -- его собственное значение.
Тогда кратность $\lambda$ в характеристическом многочлене $\chi_\varphi$ называется кратностью собственного значения.
\end{definition}

Почему это определение имеет смысл, вы увидите чуть позже, когда мы будем говорить про диагонализацию (утверждение~\ref{claim::DiagCrit}).


\begin{claim}
Пусть $F$ -- алгебраически замкнутое поле, $V$ -- векторное пространство над полем $F$ и $\varphi\colon V\to V$ -- линейный оператор.
Тогда обязательно существует ненулевой собственный вектор $v\in V$ для некоторого $\lambda\in F$.
\end{claim}
\begin{proof}
Действительно, наличие такого вектора означает, что для некоторого $\lambda\in F$ пространство $V_\lambda$ не нулевое.
А это по предыдущему утверждению равносильно тому, что $\lambda$ -- корень характеристического многочлена для $\varphi$.
Так как этот многочлен не константный (его степень равна размерности пространства),%
\footnote{Мы скромно закроем глаза на случай $V = 0$, то есть пространство нульмерно.
В этом случае большой вопрос, что считать спектром.
Правильно полагать его пустым.
Верность утверждения тогда зависит от аккуратности формулировки.
Но не надо забивать себе этим голову, просто имейте в виду, что иногда этот случай нужен.}
а $F$ -- алгебраически замкнуто, то у нас обязательно существует корень $\lambda\in F$.
А значит $V_\lambda \neq 0$ (по утверждению~\ref{claim::EigenSpec}).
\end{proof}

% TO DO
% Убрать корневые
\begin{definition}
Пусть $V$ -- некоторое векторное пространство над полем $F$ и $\varphi \colon V\to V$ -- линейный оператор.
Для любого числа $\lambda \in F$ определим корневое подпространство
\[
V^\lambda = \{v\in V\mid \exists n:\,(\varphi - \lambda\Identity)^n v = 0\}
\]
\end{definition}

\paragraph{Замечания}

\begin{itemize}
\item Заметим, что  $V^\lambda=\bigcup_{n\geqslant 0}\ker (\varphi - \lambda \Identity)^n$.
Каждое из ядер является подпространством.
Однако в общем случае объединение подпространств не является подпространством.
Но в данном случае $\ker(\varphi - \lambda \Identity)^k\subseteq \ker(\varphi-\lambda \Identity)^{k+1}$, то есть наши подпространства возрастают.
Я оставлю в качестве упражнения убедиться, что при таком условии объединение обязательно будет подпространством.
 
\item Кроме того, по определению $V_\lambda \subseteq V^\lambda$.
При этом равенства в этом включении может не быть.
Пусть 
\[
A = 
\begin{pmatrix}
{0}&{1}\\
{0}&{0}
\end{pmatrix}
\]
Тогда $A\colon F^2\to F^2$ -- линейный оператор.
При этом $A^2 = 0$.
То есть $f(x) = x^2$ -- зануляющий многочлен.
Заметим, что он обязательно минимальный.
А значит $\spec(A) = \{0\}$.
Тогда $V_0 = \ker A$ и оно порождено вектором $e_1$.
С другой стороны $F^2 = \ker A^2$, а потому $V^0 = F^2$.

\item Обратите внимание, что $V_\lambda \neq 0$ тогда и только тогда, когда $V^\lambda\neq 0$.
В одну сторону -- это следует из вложения $V_\lambda\subseteq V^\lambda$.
В другую сторону, если $v\in V^\lambda$ и $v\neq 0$, то найдем такое $k$, что $w =(\varphi - \lambda\Identity)^k v \neq 0 $, а $(\varphi - \lambda \Identity)w = (\varphi - \lambda\Identity)^{k+1}v =0$.
Тогда $w\in V_\lambda$ и не нулевой.

\item Подпространства $V_\lambda$ и $V^\lambda$ являются $\varphi$ инвариантными для любого $\lambda$.

\end{itemize}


\subsection{Лемма о стабилизации}

\begin{claim}
\label{claim::StabilityLemma}
Пусть $V$ -- векторное пространство над полем $F$ и $\varphi \colon V\to V$ -- линейный оператор.
Тогда
\begin{enumerate}
\item Найдется такое число $0\leqslant k\leqslant \dim_F V$, что
\[
0\subsetneq \ker \varphi \subsetneq \ker \varphi^2\subsetneq \ldots \subsetneq \ker\varphi^k = \ker \varphi^{k+1} = \ldots
\]

\item
Найдется такое число $0\leqslant k\leqslant \dim_F V$, что
\[
 V \supsetneq \Im \varphi \supsetneq \Im \varphi^2 \supsetneq \ldots \supsetneq \Im\varphi^k = \Im \varphi^{k+1} = \ldots
\]
\end{enumerate}
\end{claim}

Давайте поясним, что утверждается.
Мы говорим, что ядра оператора сначала строго растут, а начиная с какого-то момента обязательно становятся одинаковыми для всех последующих шагов.
Аналогичное происходит с образами, только они сначала строго уменьшаются, а потом становятся одинаковыми.
Стоит обратить внимание, что $k$ может быть равным $0$, это означает, что нет строгих включений и равенства начинаются с самого начала.

\begin{proof}

(1) Нам достаточно показать, что если в какой-то момент $\ker \varphi^m = \ker\varphi^{m+1}$, то $\ker \varphi^{m+1} = \ker\varphi^{m+2}$.
Включение $\ker \varphi^{m+1}\subseteq \ker \varphi^{m+2}$ понятно из определения (если что-то зануляется $\varphi^{m+1}$, то оно зануляется и большей степенью $\varphi^{m+2}$).
Надо показать обратное.
Пусть $v\in \ker \varphi^{m+2}$, тогда $\varphi^{m+2}v = 0$.
То есть $\varphi^{m+1}(\varphi v) = 0$.
Это значит $\varphi v \in \ker \varphi^{m+1} = \ker \varphi^m$.
Последнее означает, что $\varphi^m(\varphi v) = 0$, то есть $\varphi^{m+1} v = 0$.
Значит $v\in \ker \varphi^{m+1}$, что и требовалось.

Теперь надо понять, что $k$ не превосходит размерность $V$.
Но это следует из того факта, что в цепочке
\[
0\subsetneq \ker \varphi \subsetneq\ker\varphi^2\subsetneq \ldots
\]
размерность подпространств каждый шаг растет хотя бы на единицу.
Значит больше, чем $\dim_F V$ шагов у нас быть не может.

(2) Доказательство этого факта проходит аналогично.
Либо можно воспользоваться на соотношение между размерностями ядра и образа (утверждение~\ref{claim::ImKer} пункт~(3)) и увидеть, что стабилизация у образов начинается на том же значении $k$, что и у ядер.
\end{proof}

\paragraph{Замечание}

В силу этого утверждения мы получаем, что $V^\lambda = \ker (\varphi - \lambda \Identity)^m$ для некоторого достаточно большого $m$.
Понятно, что на самом деле, достаточно взять $m = \dim_F V$.%
\footnote{Если уж бы до конца честным, то можно еще сильнее уменьшить $m$.
Тут достаточно взять кратность собственного значения в минимальном многочлене, я докажу это позже.}


\newpage
\section{Классификационная задача для линейных отображений}

Абстрактные объекты вроде векторных пространств и линейных отображений между ними становятся более знакомыми после выбора базиса.
Пространства превращаются в столбцы, а отображения в матрицы.
Но так как базис выбирать можно по-разному, то и матрицы в такой ситуации получаются черт знает какими.
Основной вопрос классификационной задачи: как понять по матрицам, что они задают одно и то же линейное отображение, но в разных базисах.
Есть два принципиальных по сложности случая: когда линейное отображение бьет между разными пространствами и когда оно действует в одном пространстве (случай линейного оператора).
Разберем их по-отдельности.

\subsection{Классификация для линейных отображения между разными пространствами}

Напомню, что если $\varphi \colon V\to U$ -- линейное отображение между векторными пространствами над некоторым полем $F$.
То после выбора базиса $e$ в $V$ и базиса $f$ в $U$ линейное отображение $\varphi$ превращается в матрицу $A\in \operatorname{M}_{m\,n}(F)$, где $n = \dim_F V$ и $m = \dim_F U$.
Если же мы выберем другие базисы $e'$ и $f'$ в пространствах $V$ и $U$, соответственно, то $\varphi$ превратится в матрицу $A'$.
Если $e' = eC$ и $f' = fD$, где $C\in \operatorname{M}_n(F)$ и $D\in\operatorname{M}_m(F)$ -- матрицы перехода к новым базисам, то $A' = D^{-1}A C$.

\begin{claim}
\label{claim::HomClassification}
Пусть $V$ и $U$ -- векторные пространства над полем $F$ размерностей $n$ и $m$, соответственно, и пусть нам даны матрицы $A, B\in \operatorname{M}_{m\,n}(F)$.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item Существует линейное отображение $\varphi\colon V\to U$ и базисы $e$ и $e'$ в $V$, $f$ и $f'$ в $U$ такие, что $A$ будет матрицей $\varphi$ в базисах $e$ и $f$, а $B$ будет матрицей $\varphi$ в базисах $e'$ и $f'$.

\item $\rk A = \rk B$.
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Rightarrow$(2).
Здесь есть два доказательства: идейное и техническое.
Я приведу оба.
Давайте начнем с технического.
Оно проще в понимании.

\textbf{Техническое доказательство.} Если такой $\varphi$ и базисы существуют, то $B = D^{-1}AC$ для некоторых невырожденных матриц $C$ и $D$ подходящего размера.
Тогда мы знаем по утверждению~\ref{claim::rkInvariance}, что $\rk A = \rk B$, так как ранг не меняется при умножении на обратимую матрицу слева и справа.

\textbf{Идейное доказательство.} Если зафиксировать базисы $e$ и $f$ в пространствах $V$ и $U$ соответственно, то $\varphi \colon V\to U$ превращается в $A\colon F^n \to F^m$.
Тогда образ $\varphi$ совпадает с линейной оболочкой столбцов матрицы $A$.
А значит $\rk A = \dim_F \Im \varphi$.
Аналогично, $\rk B = \dim_F \Im \varphi$.

(2)$\Rightarrow$(1).
Нам дано, что у матриц $A$ и $B$ равны ранги, а нам надо построить линейное отображение $\varphi\colon V\to U$ и еще пары базисов, чтобы в них матрицы $\varphi$ совпали с $A$ и $B$.

Так как $\rk A = \rk B$, мы можем найти обратимую матрицу $D\in \operatorname{M}_m(F)$ и обратимую матрицу $C\in \operatorname{M}_n(F)$ такие, что $B = D^{-1}AC$.
 Действительно, мы можем преобразованиями строк и столбцов матрицу $A$ привести к виду $R = \left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$, где $E$ имеет размер $\rk A$.
 То есть $A = D_1 R C_1$.
 Аналогично, $B = D_2 R C_2$.
 Выразим $R$ из первого равенства и подставим во второе.
 Получим требуемое.

Теперь выберем произвольный базис $e$ в $V$ и произвольный базис $f$ в $U$.
Чтобы задать линейное отображение из $V$ в $U$ нам надо отправить каждый базисный вектор из $e$ куда-то в $U$ (утверждение~\ref{claim::LinMapExist}).
Сделаем это так: $\varphi e = f A$.
Тогда мы задали линейное отображение $\varphi \colon V\to U$ такое, что в базисах $e$ и $f$ он имеет матрицу $A$.

Далее положим $e' = eC$ и $f' = fD$.
По утверждению~\ref{claim::BasisClassification} о классификации базисов, из обратимости $C$ и $D$ следует, что $e'$ и $f'$ -- тоже базисы.
Тогда оператор $\varphi$ в этих базисах будет иметь матрицу $D^{-1}AC$, которая равна $B$ по построению.
Мы сделали все, что требовалось.
\end{proof}


\subsection{Анонс классификационной задачи для линейных операторов}

Пусть теперь $\varphi\colon V\to V$ -- линейный оператор, т.е. линейное отображение из векторного пространства в себя.
Тогда при выборе базиса $e$ в $V$ наш оператор превращается в матрицу $A\in \operatorname{M}_n(F)$, где $n = \dim_F V$.
Если же мы выберем другой базис $e'$ в $V$ такой, что $e' = eC$ для некоторой обратимой $C \in \operatorname{M}_n(F)$.
То матрица $\varphi$ в базисе $e'$ будет $C^{-1}AC$.
Заметим сложность ситуации.
Мы теперь не можем независимо домножать нашу матрицу с разных сторон на разные матрицы.
Если думать в терминах элементарных преобразований, мы теперь должны неким сложным образом согласовывать преобразования строк и столбцов.
Из-за этих ограничений кустарными методами (вроде подбора элементарных преобразований) для приведения матрицы в хороший вид нам обойтись не получится.
Более того, степень <<хорошести>> нашей матрицы будет сильно зависеть от свойств поля $F$ над которым определены наши векторные пространства.
А так как элементарные преобразования ничего не знают про свойства поля, то это автоматически означает, что не мы такие неумелые, что не смогли воспользоваться элементарными преобразованиями, а этот метод в лоб просто не работает.

Для преодоления сложившихся трудностей в случае оператора приходится привлекать более продвинутую технику.
К такой технике как раз и относятся собственные векторы и значения, собственные и корневые подпространства.
Кульминацией для нас будет теорема о жордановой нормальной форме.
Формулировать мы ее пока не будем, но обсудим некоторые стратегические соображения.

Для чего вообще меняется базис?
Для того, чтобы сделать вид матрицы линейного оператора максимально простым.
Тогда заменив его простой матрицей, его будет проще изучать.
В идеале простой вид -- это когда много нулей.
Самый желанный для нас вид -- диагональный.
Было бы еще лучше, если бы можно было сделать матрицу диагональной с единицами и нулями на диагонали, но это совсем не возможно.
Например, если оператор не вырожден, то его определитель не меняется, а он совпадает с произведением диагональных элементов матрицы.
То есть скалярную матрицу $\lambda E$ никогда нельзя сделать единичной $E$ путем замены базиса (это так же видно из формулы замены) если $\lambda \neq 1$.

 Оказывается и диагональной можно сделать не всякую матрицу путем сопряжения, то есть не всякий линейный оператор приводится к диагональному виду в каком-то базисе.
 Потому один из первых вопросов, которым мы хотим заняться -- это вопрос: когда линейный оператор задается диагональной матрицей в некотором базисе.
 

\subsection{Диагонализуемость линейного оператора}

\begin{definition}
Пусть $\varphi\colon V\to V$ -- линейный оператор над некоторым полем $F$.
Будем говорить, что $\varphi$ диагонализуется или диагонализируемый, если в некотором базисе его матрица является диагональной.
\end{definition}

\begin{claim}
\label{claim::EigenRootInd}
Пусть $\varphi\colon V\to V$ -- линейный оператор в некотором векторном пространстве над полем $F$ и пусть $\lambda_1,\ldots,\lambda_k\in F$ -- различные числа.
Тогда
\begin{enumerate}
\item Пространства $V_{\lambda_1},\ldots,V_{\lambda_k}$ линейно независимы.%
\footnote{Определение линейное независимости подпространств~\ref{def::IndepSpaces}.}
${}^{,\,}$%
\footnote{Прошу обратить внимание, что линейно независимые подпространства могут быть нулевыми или часть из них может быть нулевыми.}

\item Пространства $V^{\lambda_1},\ldots,V^{\lambda_k}$ линейно независимы.
\end{enumerate}
\end{claim}
\begin{proof}
1) В начале покажем случай собственных подпространств.
Пусть $u_1\in V_{\lambda_1},\ldots,u_k\in V_{\lambda_k}$ -- произвольные ненулевые векторы такие, что $u_1 + \ldots + u_k = 0$.
Применим к этому равенству оператор $\varphi - \lambda_1\Identity$.
Тогда $u_1$ занулится, а $(\varphi - \lambda_1\Identity)u_i = (\lambda_i - \lambda_1)u_i$ будет ненулевым вектором из $V_{\lambda_i}$ при $i \neq 1$.
Обозначим эти векторы за $u_2',\ldots,u_k'$.
Тогда мы доказали, что если у нас дана сумма из $k$ ненулевых векторов $u_1+\ldots+u_k = 0$, то мы можем получить более короткую сумму из $k - 1$ вектора $u_2'+\ldots+u_k' = 0$.


2) Теперь давайте разберемся с корневыми.
Пусть $v_1,\ldots,v_s$ -- набор векторов такой, что $v_i\in V^{\lambda_i}$ и $v_1 + \ldots + v_s = 0$, где $s$ -- самое маленькое из возможных.
Если $s = 1$, то имеем $v_1 = 0$ и доказывать нечего.

Теперь считаем, что у нас $s > 1$.
Так как $v_s$ -- корневой, то для некоторого $m$ получаем $(\varphi - \lambda_s\Identity)^m v_s = 0$.
Тогда получим
\[
(\varphi - \lambda_s\Identity)^m v_1 + \ldots + (\varphi - \lambda_s\Identity)^m v_{s-1} = 0
\]
Если мы покажем, что $(\varphi - \lambda_s\Identity)^m v_i$ лежит в $V^{\lambda_i}$ и хотя бы одно из них не ноль, то мы придем к противоречию, так как получим более короткую сумму корневых векторов, дающую ноль.

Каждое подпространство $V^{\lambda_i}$ является $\varphi$ инвариантным.
А значит и $\varphi - \lambda_s \Identity$ инвариантным.
А значит и $(\varphi - \lambda_s \Identity)^m$ инвариантным.
Это показывает, что все слагаемые действительно остаются внутри соответствующего $V^{\lambda_i}$.

Теперь проверим, что хотя бы одно из слагаемых не равно нулю.
Давайте покажем более сильное утверждение, если $v_i \neq 0$, то и $(\varphi - \lambda_s \Identity)^m v_i \neq 0$.
По определению корневого пространства, мы можем найти такое $d$, что
\[
(\varphi - \lambda_i \Identity)^d v_i = 0
\quad\text{и}\quad
u_i = (\varphi - \lambda_i \Identity)^{d-1} v_i \neq 0
\]
В частности $(\varphi - \lambda_i \Identity)u_i = 0$, то есть $u_i$ -- собственный вектор.
Чтобы показать, что $(\varphi - \lambda_s \Identity)^m v_i $ не нулевой, достаточно показать, что
\[
(\varphi - \lambda_i \Identity)^{d-1}(\varphi - \lambda_s \Identity)^m v_i \neq 0
\]
Действительно,
\[
(\varphi - \lambda_i \Identity)^{d-1}(\varphi - \lambda_s \Identity)^m v_i =
(\varphi - \lambda_s \Identity)^m (\varphi - \lambda_i \Identity)^{d-1}v_i =
(\varphi - \lambda_s \Identity)^m u_i
\]
Но по определению $u_i$ -- собственный вектор с собственным значением $\lambda_i$.
Это значит, что умножение на $\varphi$ совпадает с умножением на $\lambda_i$ на векторе $u_i$.
Значит
\[
(\varphi - \lambda_s \Identity)^m u_i = (\lambda_i - \lambda_s)^m u_i \neq 0
\]
\end{proof}
