\ProvidesFile{lecture18.tex}[Лекция 18]


\begin{claim}
\label{claim::DiagCrit}
Пусть $\varphi\colon V\to V$ -- некоторый линейный оператор в векторном пространстве над полем $F$.
Тогда следующие утверждения эквивалентны:
\begin{enumerate}
\item Оператор $\varphi$ диагонализуем.

\item Существует базис из собственных векторов.

\item Существует разложение $V = V_{\lambda_1}\oplus \ldots \oplus V_{\lambda_k}$.

\item 
\begin{enumerate}
\item Характеристический многочлен раскладывается на линейные множители 
\[
\chi_{\varphi}(t) = (t - \lambda_1)^{r_1} \ldots (t - \lambda_k)^{r_k}
\]

\item для каждого $i$ верно $\dim_F V_{\lambda_i} = r_i$.
\end{enumerate}
\end{enumerate}
\end{claim}
\begin{proof}
(1)$\Leftrightarrow$(2).
Пусть $e$ -- некоторый базис $V$.
Тогда $\varphi e = e A$, где $A$ -- матрица $\varphi$ в базисе $e$.
По определению $\varphi$ диагонализуем в базисе $e$ тогда и только тогда, когда $A$ диагональная.
С другой стороны, все векторы в $e$ собственные тогда и только тогда, когда $A$ диагональная.

(2)$\Rightarrow$(3).
Пусть $e$ -- базис из собственных векторов и $\varphi e = e A$, где $A$ -- диагональная с числами $\lambda_1,\ldots,\lambda_k$ на диагонали (эти числа могут повторяться).
Для удобства переупорядочим вектора так, чтобы одинаковые числа $\lambda_i$ шли по-порядку.
Тогда базис $e$ можно разеделить на части $e = e_1 \sqcup \ldots \sqcup e_k$, где все векторы из $e_i$ являются собственными с собственным значением $\lambda_i$.
Значит $\langle v\mid v\in e_i\rangle\subseteq V_{\lambda_i}$.
А значит 
\[
V = \langle e \rangle = \sum_i \langle e_i\rangle \subseteq  \sum_i V_{\lambda_i} \subseteq V
\]
То есть мы показали, что $V = \sum_i V_{\lambda_i}$ является суммой.
С другой стороны, утверждение~\ref{claim::EigenRootInd} гарантирует, что векторные подпространства $V_{\lambda_i}$ линейно независимы, а значит сумма прямая (одно из эквивалентных определений утверждению~\ref{claim::DirectSum}).

(3)$\Rightarrow$(2).
Пусть $V = V_{\lambda_1}\oplus \ldots \oplus V_{\lambda_k}$ и пусть $e_i$ -- какой-нибудь базис $V_{\lambda_i}$.
Тогда по одному из эквивалентных определений прямой суммы (утверждение~\ref{claim::DirectSum}) $e = e_1 \sqcup\ldots \sqcup e_k$ будет базисом для $V$.
Тогда это и есть базис из собственных векторов.

(3)$\Rightarrow$(4).
Выберем как в предыдущем пункте базис $e_i$ в каждом слагаемом $V_{\lambda_i}$.
Тогда $|e_i| = \dim_F V_{\lambda_i}$.
Запишем матрицу нашего оператора в этом базисе в блочном виде
\[
\varphi(e_1,\ldots,e_k)
=
(e_1,\ldots,e_k)
\begin{pmatrix}
{\lambda_1 E}&{}&{}\\
{}&{\ddots}&{}\\
{}&{}&{\lambda_k E}
\end{pmatrix}
\]
где размеры блоков равны в точности $r_i=|e_i| = \dim_F V_{\lambda_i}$.
Тогда характеристический многочлен $\chi_\varphi(t) = (t-\lambda_1)^{r_1}\ldots(t-\lambda_k)^{r_k}$.
Как мы видим многочлен разложился на линейные множители и кратности корней совпали с размерностями $V_{\lambda_i}$.

(4)$\Rightarrow$(3).
Пусть $\lambda_1,\ldots,\lambda_k$ -- все корни характеристического многочлена.
Тогда по утверждению~\ref{claim::EigenRootInd} сумма $V_{\lambda_1}+\ldots +V_{\lambda_k}$ всегда прямая.
То есть мы имеем $V_{\lambda_1}\oplus \ldots \oplus V_{\lambda_k}\subseteq V$.
И осталось лишь проверить равенство.
Для этого посчитаем размерности.
С одной стороны $\dim_F V = \deg \chi_\varphi$ по определению.
С другой стороны размерность левой части есть
\[
\sum_{i}\dim_F V_{\lambda_i} = \sum_i r_i = \deg_\varphi
\]
В первом равенстве мы воспользовались вторым условием, а во втором равенстве первым (если многочлен разложился на линейные множители, то сумма кратностей его корней равна степени).
Значит обе размерности совпали и пространства оказались равны.
\end{proof}

\paragraph{Примеры}
\begin{enumerate}
\item Рассмотрим оператор $A\colon \mathbb R^2 \to \mathbb R^2$ по правилу $x\mapsto Ax$, где $A =\left( \begin{smallmatrix}{a}&{-b}\\{b}&{a}\end{smallmatrix}\right)$, $a, b\in\mathbb R$.
Если $b\neq 0$ то этот оператор не диагонализуется, потому что его хар многочлен имеет только комплексные корни $a+bi$ и $a - bi$ и не имеет вещественных.
Значит не выполняется пункт 4(a).

\item Теперь рассмотрим оператор заданный той же матрицей, но в случае комплексного векторного пространства $A\colon \mathbb C^2 \to \mathbb C^2$ по правилу $x\mapsto Ax$, где $A =\left( \begin{smallmatrix}{a}&{-b}\\{b}&{a}\end{smallmatrix}\right)$, $a, b\in\mathbb R$.
Этот оператор диагонализуется и в некотором базисе записывается в виде $\left( \begin{smallmatrix}{a + bi}&{0}\\{0}&{a-bi}\end{smallmatrix}\right)$.

\item Теперь рассмотрим оператор $A\colon \mathbb C^2 \to \mathbb C^2$ по правилу $x\mapsto Ax$, где $A =\left( \begin{smallmatrix}{0}&{1}\\{0}&{0}\end{smallmatrix}\right)$.
Тогда его характеристический многочлен $\chi_A(t) = t^2$ раскладывается на линейные множители.
Число $\lambda = 0$ является единственной точкой спектра, то есть это единственное собственное значение.
Собственное подпространство $V_\lambda$ для $\lambda = 0$ задается $\{x\in \mathbb C^2\mid Ax = 0\}$, которое совпадает с $\langle e_1 \rangle$.
То есть $\dim V_\lambda$ не равно кратности корня, то есть он не диагонализуется даже над $\mathbb C$.
\end{enumerate}

Таким образом мы видим, что диагонализуемость зависит от поля.
Часть причин недиагонализуемости -- плохой выбор поля.
В этом случае в утверждении~\ref{claim::DiagCrit} не выполняется условие 4(a).
Такая проблема решается расширением поля до алгебраически замкнутого поля (так всегда можно сделать).
Но последний пример показывает, что существуют операторы, которые не диагонализуются над любым полем.
Это по-настоящему недиагонализуемые операторы.
А действительно важное препятствие к диагонализуемости -- это условие 4(b).
Другими словами условие 4(b) означает, что размерность собственного подпространства должна совпасть с кратностью соответствующего собственного значения.


\subsection{Свойства ограничения оператора}

Теперь нам надо освоить несколько мелких технических утверждений связанных с поведением различных характеристик ограничения оператора на инвариантное подпространство.

\begin{claim}
Пусть $\varphi\colon V\to V$ -- линейный оператор и $U\subseteq V$ -- инвариантное подпространство.
Тогда
\begin{enumerate}
\item Если $\varphi$ обратим, то $\varphi|_U$ обратим.

\item $\spec_F \varphi|_U\subseteq \spec_F \varphi$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Если $\varphi$ обратим, то $\ker \varphi = 0$, тогда $\ker \varphi|_U = \ker \varphi \cap U = 0$.
А значит $\varphi|_U$ обратим по утверждению~\ref{claim::OperatorInvert}.

(2) Нам надо показать, что если $\lambda\notin\spec_F \varphi$, то $\lambda\notin\spec_F \varphi|_U$.
То есть если $\varphi-\lambda\Identity$ обратим, то и $\varphi|_U-\lambda \Identity$ обратим.
Но это следует из первого пункта и наблюдения 
\[
(\varphi - \lambda \Identity)|_U = \varphi|_U -(\lambda\Identity)|_U = \varphi|_U - \lambda \Identity
\]
\end{proof}



\begin{claim}
\label{claim::RestrictionChar}
Пусть $V = U\oplus W$, $\varphi\colon V\to V$ -- линейный оператор и подпространства $U$ и $W$ являются $\varphi$-инвариантными.
Тогда
\begin{enumerate}
\item $\tr \varphi = \tr \varphi|_U + \tr \varphi|_W$.

\item $\det \varphi = \det \varphi|_U \det \varphi|_W$.

\item $\chi_\varphi(t) = \chi_{\varphi|_U}(t) \chi_{\varphi|_W}(t)$.

\item $\spec_F \varphi = \spec_F \varphi|_U \cup \spec_F \varphi|_W$.
\end{enumerate}
\end{claim}
\begin{proof}
Пусть $e$ -- базис $U$ и $f$ -- базис $W$.
Тогда по одному из эквивалентных определений прямой суммы (утверждение~\ref{claim::DirectSum}) $e \cup f$ будет базисом $V$.
Давайте запишем в этом базисе наш оператор $\varphi$:
\[
\varphi(e,f) = (e,f)
\begin{pmatrix}
{A}&{B}\\
{C}&{D}
\end{pmatrix}
\]
Так как подпространство $U =\langle r \rangle$ $\varphi$-инвариантно, то есть $\varphi(U)\subseteq U$, то $\varphi(e)$ выражается только через $e$.
Последнее означает, что $C = 0$.
Аналогично, так как $W$ $\varphi$-инвариантно, то $B = 0$.
А значит
\[
\varphi(e,f) = (e,f)
\begin{pmatrix}
{A}&{0}\\
{0}&{D}
\end{pmatrix}
\]
При этом по определению $A$ -- это матрица $\varphi|_U$ в базисе $e$, а $D$ -- это матрица $\varphi|_W$ в базисе $f$.
Тогда все четыре утверждения следуют из явного подсчета следа, определителя, характеристического многочлена и спектра для блочно диагональных матриц.
\end{proof}

\subsection{Приведение к верхнетреугольному виду}

\begin{claim}
Пусть $\varphi \colon V\to V$ -- линейный оператора в векторном пространстве размерности $n$ над полем $F$ и пусть $\lambda\in F$ -- корень минимального многочлена для $\varphi$.
Тогда существует базис, в котором матрица $\varphi$ имеет следующий блочный вид
\[
A_\varphi = 
\begin{pmatrix}
{\lambda}&{*}\\
{0}&{B}
\end{pmatrix},\text{ где }
B\in \operatorname{M}_{n-1}(F)
\]
\end{claim}
\begin{proof}
Пусть $f_{\text{min}}=(t-\lambda)g(t)$.
Тогда $g(\varphi) \neq 0$, то есть $g(\varphi)$ -- ненулевой оператор.
Последнее означает, что для какого-то вектора $v\in V$, $g(\varphi)v\neq 0$.
Обозначим $u = g(\varphi)v$.
Тогда это ненулевой вектор.
С другой стороны
\[
(\varphi - \lambda \Identity)u = (\varphi - \lambda \Identity)g(\varphi)v = f_\text{min}(\varphi)v = 0
\]
То есть $u$ -- ненулевой собственный вектор с собственным значением $\lambda$.
Раз это ненулевой вектор, то множество $\{u\}$ линейно независимое.
А значит его можно дополнить до базиса.
Пусть это будет $u,u_2,\ldots,u_n$.
Тогда в этом базисе матрица оператора $\varphi$ будет иметь заявленный вид.
Действительно, по определению
\[
\varphi(u, u_2,\ldots, u_n) = (u, u_2,\ldots,u_n)
\begin{pmatrix}
{a}&{*}\\
{w}&{B}
\end{pmatrix}
\]
Тогда $\varphi u = a u + (u_2, \ldots, u_n)w$.
Но мы уже знаем, что $\varphi u = \lambda u$.
То есть $a = \lambda$ и $w = 0$.
\end{proof}

\begin{claim}
\label{claim::OperatorUpperTriangle}
Пусть $\varphi\colon V\to V$ -- линейный оператор в векторном пространстве над полем $F$ и пусть минимальный многочлен $f_{\text{min}}$ для $\varphi$ раскладывается на линейные множители $(t-\lambda_1)^{k_1}\ldots (t-\lambda_r)^{k_r}$.
Тогда существует базис в $V$ такой, что матрица $\varphi$ верхнетреугольная с числами $\lambda_1,\ldots,\lambda_r$ на диагонали (возможно с повторениями).
\end{claim}
\begin{proof}
Я не смогу вам дать доказательство полностью на языке операторов, так как мы не владеем некоторыми необходимыми техническими средствами в виде фактор пространств и фактор операторов.
Потому надо будет переформулировать все в терминах матриц.

В начале выберем случайный базис в $V$.
Тогда наш оператор превратится в $A\colon F^n \to F^n$.
Нам надо найти такую обратимую матрицу $D\in \operatorname{M}_n(F)$, что $D^{-1}AD$ будет верхне треугольной с числами $\lambda_1,\ldots, \lambda_r$ на диагонали (может быть с повторениями).


Начнем.
Так как минимальный многочлен раскладывается на линейные, то он имеет корень, например, выберем $\lambda_1$.
Тогда предыдущее утверждение означает, что можно найти обратимую матрица $C\in \operatorname{M}_n(F)$ такую, что
\[
C^{-1}AC =
\begin{pmatrix}
{\lambda_1}&{*}\\
{0}&{B}
\end{pmatrix}
\]
По формулам для вычисления многочленов от блочных верхне треугольных матриц (утверждение~\ref{claim::PolyOfUpperBlock}) мы знаем, что $f_\text{min}$ зануляет блок $B$.
То есть минимальный многочлен для $B$ тоже раскладывается на линейные множители и его корни находятся среди корней $f_\text{min}$, так как минимальный для $B$ делит $f_\text{min}$.
А значит, для $B$ по индукции найдется такая обратимая матрица $T\in \operatorname{M}_{n-1}(F)$, что $T^{-1}BT$ является верхне треугольной с числами $\lambda_1,\ldots,\lambda_r$ на диагонали (быть может с повторениями и пропусками).
Тогда
\[
\begin{pmatrix}
{1}&{}\\
{}&{T}
\end{pmatrix}^{-1}
C^{-1}AC
\begin{pmatrix}
{1}&{}\\
{}&{T}
\end{pmatrix}
=
\begin{pmatrix}
{1}&{}\\
{}&{T}
\end{pmatrix}^{-1}
\begin{pmatrix}
{\lambda_1}&{*}\\
{0}&{B}
\end{pmatrix}
\begin{pmatrix}
{1}&{}\\
{}&{T}
\end{pmatrix}=
\begin{pmatrix}
{\lambda_1}&{*}\\
{0}&{T^{-1}BT}
\end{pmatrix}
\]
Последняя матрица верхне треугольная с числами $\lambda_1,\ldots,\lambda_r$ на диагонали (быть может с повторениями).
То есть мы доказали, что хотели с матрицей
\[
D = C 
\begin{pmatrix}
{1}&{}\\
{}&{T}
\end{pmatrix}
\]
\end{proof}

\begin{claim}
\label{claim::CharPolyOnRootSpace}
Пусть $\varphi\colon V\to V$ -- некоторый линейный оператор на векторном пространстве $V$ над полем $F$.
Тогда $\chi_{\varphi|_{V^\lambda}} (t) = (t - \lambda)^{\dim V^\lambda}$.
\end{claim}
\begin{proof}
Оператор $\varphi|_{V^\lambda}$ зануляется многочленом вида $(t-\lambda)^d$.
Значит его минимальный многочлен имеет вид $(t-\lambda)^k$.
По утверждению~\ref{claim::OperatorUpperTriangle} матрица оператора $\varphi|_{V^\lambda}$ приводится к верхнетреугольному виду с $\lambda$ на диагонали.
А значит $\chi_{\varphi|_{V^\lambda}}(t) = (t - \lambda)^{\dim V^{\lambda}}$.
\end{proof}

\subsection{Идеальный спектр}

\begin{definition}
Пусть $\varphi \colon V\to V$ -- линейный оператор над произвольным полем $F$, тогда идеальный спектр $\varphi$ это следующее множество:
\[
\spec_F^I\varphi :=\{p\in F[t]\mid p\text{ -- неприводим со старшим коэффициентом } 1 \text{ и } p(\varphi)\text{ необратим}\}
\]
\end{definition}

\paragraph{Пример} Если рассмотреть линейный оператор $A\colon \mathbb R^2\to \mathbb R^2$ заданный матрицей $A = \left(\begin{smallmatrix}{0}&{-1}\\{1}&{0}\end{smallmatrix}\right)$, то его минимальный многочлен будет $f = x^2 +1$.
Таким образом вещественный спектр пуст $\spec_\mathbb R A = \varnothing$, так как $f$ неприводим и не линеен, а значит не имеет корней.
Однако идеальный спектр будет непустым $\spec_\mathbb R^I A = \{x^2 + 1\}$.


\begin{claim}
Пусть $\varphi\colon V\to V$ -- некоторый оператор над произвольным полем $F$ и $f_\text{min}$ -- его минимальный зануляющий многочлен над $F$.
Тогда
\begin{enumerate}
\item Для любого зануляющего многочлена $f$ и любого $p\in \spec_F^I \varphi$ следует, что $p$ делит $f$.

\item $p\in \spec_F^I \varphi$ тогда и только тогда, когда $p$ делит $f_{\text{min}}$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Для этого достаточно показать, что если $p$ не делит $f$, то $p(\varphi)$ обратим.
Действительно, так как $p$ неприводим, это означает, что $f$ и $p$ взаимно просты.
Тогда по расширенному алгоритму Евклида мы знаем, что $1 = u(t) p(t) + v(t) f(t)$ для некоторых многочленов $u(t), v(t)\in F[t]$.
Тогда подставив в последнее равенство $\varphi$ мы видим 
\[
\Identity = u(\varphi) p(\varphi) + v(\varphi) f(\varphi) = u(\varphi) p(\varphi)
\]
То есть $u(\varphi)$ -- обратный к $p(\varphi)$, что и требовалось.

(2) Пусть теперь $f_\text{min}$ -- минимальный многочлен и пусть $p$ -- неприводимый делитель $f_\text{min}$, то есть $f_\text{min} = p h$.
Надо показать, что $p(\varphi)$ необратим.

Мы знаем, что $0 = f_\text{min}(\varphi) = p(\varphi) h(\varphi)$.
Предположим, что $p(\varphi)$ обратим.
Тогда в равенстве $p(\varphi)h(\varphi) = 0$ можно сократить на $p(\varphi)$.
Значит $h(\varphi) = 0$, что противоречит минимальности степени $f_\text{min}$.
\end{proof}


\paragraph{Замечания}
\begin{itemize}
\item Пусть $f_{\text{min}}$ раскладывается на линейные множители
\[
f_{\text{min}}(t) = (t - \lambda_1)^{k_1}\ldots(t-\lambda_r)^{k_r}
\]
Тогда идеальный спектр $\varphi$ -- это в точности многочлены $\{t-\lambda_1,\ldots,t-\lambda_r\}$.
То есть каждый элемент идеального спектр однозначно соответствует элементу обычного спектра $\spec_F\varphi = \{\lambda_1,\ldots,\lambda_r\}$.
Потому идеальный спектр можно рассматривать как обобщение понятия спектра на случай, когда в минимальном многочлене есть нелинейные множители.

\item Последнее утверждение можно рассматривать как обобщение утверждений~\ref{claim::PolyAnnihilator} и~\ref{claim::MinPoly} о том, что спектр лежит среди корней зануляющего многочлена и в точности совпадает с корнями минимального.

\item Так как минимальный многочлен делит характеристический, то любой элемент идеального спектра является делителем характеристического многочлена.

На самом деле можно показать, что элементы идеального спектра -- это в точности делители характеристического многочлена.
Но я не буду вас мучить доказательством этого утверждения нашими методами.

Давайте я намекну про правильный способ.
Пусть $\varphi\colon V\to V$ -- некоторый оператор над полем $F$ и пусть $f_\text{min} = p_1^{k_1}\ldots p_r^{k_r}$.
Предположим, что многочлен $\chi_\varphi$ имеет неприводимый делитель $p$ отличный от всех $p_i$.
Пусть $\bar F$ -- алгебраическое замыкание $F$.
Тогда можно заменить оператор $\varphi$ на его версию над $\bar F$, а именно $\varphi_{\bar F}\colon V_{\bar F}\to V_{\bar F}$, у которого будет тот же минимальный и характеристический многочлен.
Например, это можно сделать, выбрав базис в $V$, оно превращается в $F^n$, потом взять $V_{\bar F} = \bar F^n$ и в нем задать $\varphi_{\bar F}$ той же матрицей, что и $\varphi$.
Характеристический многочлен не изменится, потому что матрица та же самая, но надо пояснить, почему минимальный многочлен не изменится.
В этом случае есть общая конструкция для $V_{\bar F}$, которая определяется так, что неизменность минимального многочлена будет очевидна (можно и руками показать, выбрав базис $\bar F$ как векторного пространства над $F$).
После чего мы видим, что $f_\text{min}$ и $\chi_\varphi$ имееют одни и те же корни в $\bar F$, то есть $p$ имеет общий корень с каким-то $p_i$.
Но это не возможно.
Действительно, в силу их взаимной простоты, мы имеем $1 = u(t) p(t) + v(t) p_i(t)$.
И если у них есть общий корень, то после подстановки его в равенсто, справа будет ноль, а слева -- единица.
На этом победа.%
\footnote{В курсе алгебры вам расскажут как для любого поля $F$ и любого многочлена $g\in F[t]$ построить большее поле $L\supseteq F$ такое, что в нем $g$ раскладывается на линейные множители.
Как мы видим из доказательства, этого нам достаточно.
Остается аккуратно объяснить, почему не изменится минимальный многочлен и вы будете готовы доказать этот факт.}
\end{itemize}

\begin{claim}[БД]
Пусть $\varphi\colon V\to V$ -- некоторый оператор над произвольным полем $F$.
Тогда $p\in \spec_F^I \varphi$ тогда и только тогда, когда $p$ делит $\chi_\varphi$.
\end{claim}
