\ProvidesFile{lecture31.tex}[Лекция 31]


\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta\colon V\times V\to\mathbb C$ -- эрмитова форма.
Тогда существует базис, в котором матрица формы имеет вид
\[
B_\beta = 
\begin{pmatrix}
{E}&{}&{}\\
{}&{-E}&{}\\
{}&{}&{0}\\
\end{pmatrix}
\]
При этом количество единиц, минус единиц и нулей на диагонали не зависит от базиса.
\end{claim}
\begin{proof}
Мы уже знаем, что эрмитова форма в некотором базисе диагонализуется.
То есть существует базис, что $\beta(x, y) = \sum_{i=1}^n d_i \bar x_i y_i$, где $d_i\in \mathbb R$.
Перестановкой базисных элементов будем считать, что сначала идут все положительные коэффициенты, потом отрицательные и только потом нулевые, то есть $\beta(x,y) = \sum_{i=1}^k d_i \bar x_i y_i - \sum_{i=k+1}^r d_i \bar x_i y_i$, где все $d_i > 0$.
В этом случае сделаем замену $x_i' = \sqrt{d_i}x_i$.
Получим $\beta(x_i',y_i') = \sum_{i=1}^k \bar x_i' y_i' - \sum_{i=k+1}^r \bar x_i' y_i'$.
А значит, можно привести к такому виду.


Теперь покажем единственность.
Количество единиц и минус единиц вместе дает ранг матрицы.
А ранг матрицы билинейной формы $\beta\colon \bar V\times V\to \mathbb C$ не меняется при смене базисов (раздел~\ref{subsection::BilChar}).
Значит у нас количество нулей и суммарное количество единиц и минус единиц не зависит от базиса.
Теперь надо показать, что количество единиц и минус единиц одно и то же в каждом базисе.
Для этого надо повторить кусок доказательства соответствующего утверждения для билинейных форм над $\mathbb R$ (утверждения~\ref{claim::SBilReal}).
Я для удобства прочтения повторю его здесь.


Предположим противное -- пусть зависит.
Пусть найдутся два базиса $e_1,\ldots,e_n$ и $f_1,\ldots,f_n$, так что форма в них имеет вид
\begin{align*}
\beta(x, y) &= \bar x_1y_1+\ldots +\bar x_s y_s - \bar x_{s+1}y_{s+1} - \ldots - \bar x_k y_k\\
\beta(x',y') &= \bar x_1'y_1'+\ldots +\bar x_t' y_t' - \bar x_{t+1}' y_{t+1}' - \ldots - \bar x_k' y_k'\\
\end{align*}
Пусть для определенности $s > t$.
Тогда положим $W = \langle e_1,\ldots, e_s\rangle$ и $U = \langle f_{t+1},\ldots, f_n\rangle$.
Теперь вспомним, что для любого $v\in V$ значения $Q_\beta(v)\in \mathbb R$ в силу эрмитовости формы.
Далее заметим, что $Q_\beta(w) > 0$ для любого ненулевого $w\in W$ и $Q_\beta(u) \leqslant 0$ для любого $u\in U$.
Следовательно подпространства $W$ и $U$ могут пересекаться только по нулю.
С другой $\dim W+\dim U = s + n - t > n$, а значит $\dim(W\cap U) > 0$, противоречие.
\end{proof}

\paragraph{Замечание}

Как!
Откуда взялись эти долбаные минус единицы!?
Почему нельзя все сделать единицами как в случае билинейных форм?
Звучат эти вопросы у вас сейчас в голове?
Если да, то это правильное замечание для прочтения.
Давайте рассмотрим пример билинейной формы $\beta(x,y) = \bar x_1 y_1 - \bar x_2 y_2$.
Давайте будем думать в терминах соответствующей билинейной формы $Q_\beta(x) = |x_1|^2 - |x_2|^2$.
Теперь мы хотим сделать замену $x_1 = \lambda x_1'$ и $x_1 = \mu x_2'$.
Но тогда $Q_\beta(x') = |\lambda|^2 |x_1'|^2 - |\mu|^2 |x_2'|^2$.
То есть из под модуля комплексные числа $\lambda$ и $\mu$ вылезут положительными вещественными, потому отрицательный знак поправить так не получится.
Все дело в наличии сопряжения на координатах одного аргумента.

Как и в случае вещественного векторного пространства мы можем определить положительные и отрицательные формы.

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма.
Тогда количество единиц в ее диагональной форме $\#1$ называется положительным индексом инерции, количество минус единиц $\#-1$ называется отрицательным индексом инерции.
Количество нулей будет обозначаться $\# 0$.

Форма $\beta$ называется положительно определенной, если $Q_\beta(v) > 0$ для любого ненулевого $v\in V$.
Форма $\beta$ называется отрицательно определенной, если $Q_\beta(v)<0$ для любого ненулевого $v\in V$.
\end{definition}

Обратите внимание, что 
\begin{itemize}
\item Форма положительно определена тогда и только тогда, когда ее положительный индекс инерции равен размерности пространства, то есть $\# 1 = \dim V$.

\item Форма отрицательно определена тогда и только тогда, когда ее отрицательный индекс инерции равен размерности пространства, то есть $\#-1 = \dim V$.

\item Форма не вырождена тогда и только тогда, когда $\# 0 = 0$.
\end{itemize}


\subsection{Метод Якоби для полуторалинейных форм}

Здесь я хочу распространить метод Якоби описанный в разделе~\ref{subsection::Jacoby} на случай эрмитовых форм.
Окажется, что полуторалинейность ни на что не повлияет и метод дословно переносится и сюда.

Пусть $V$ -- векторное пространство над $\mathbb C$ и $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма.
Пусть $e_1,\ldots,e_n$ -- некоторый базис $V$, в котором форма записывается в виде $\beta(x, y) = \bar x^t B y$, где $B\in \operatorname{M}_{n}(\mathbb C)$ и $x,y\in \mathbb C^n$.
Эрмитовость формы $\beta$ означает, что $B^* = B$.%
\footnote{Такие матрицы называются самосопряженными.}
Выделим в матрице $B$ верхние левые блоки:
\[
B =
\begin{pmatrix}
{\boxed{
\begin{matrix}
{
\boxed{
\begin{matrix}
{
\boxed{
\begin{matrix}
{\boxed{b_{11}}}&{}\\
{}&{\ddots}
\end{matrix}
}
}&{}\\
{}&{B_k}
\end{matrix}
}
}&{}\\
{}&{\ddots}
\end{matrix}
}
}&{}\\
{}&{}
\end{pmatrix}
\]
То есть $B_k$ -- подматрица состоящая из первых $k$ строк и столбцов.
Определим подпространства $U_k = \langle e_1,\ldots,e_k\rangle$.
Тогда $B_k$ -- матрица формы $\beta|_{U_k}$ в базисе $e_1,\ldots,e_k$.
Обозначим $\det B_k$ через $\Delta_k$.
Наша задача найти базис $e_1',\ldots,e_n'$ такой, чтобы
\[
\begin{pmatrix}
{e_1'}&{\ldots}&{e_n'}
\end{pmatrix}
=
\begin{pmatrix}
{e_1}&{\ldots}&{e_n}
\end{pmatrix}
\begin{pmatrix}
{1}&{*}&{\ldots}&{*}\\
{}&{1}&{\ldots}&{*}\\
{}&{}&{\ddots}&{\vdots}\\
{}&{}&{}&{1}\\
\end{pmatrix}
\]
и при этом форма $\beta$ была диагональная в базисе $e_1',\ldots,e_n'$.
Заметим, что в силу специального вида замены базиса мы имеем $\langle e_1,\ldots,e_k \rangle = \langle e_1', \ldots,e_k'\rangle$.
Более того, в этом случае верно
\[
\begin{pmatrix}
{e_1'}&{\ldots}&{e_k'}
\end{pmatrix}
=
\begin{pmatrix}
{e_1}&{\ldots}&{e_k}
\end{pmatrix}
\begin{pmatrix}
{1}&{*}&{\ldots}&{*}\\
{}&{1}&{\ldots}&{*}\\
{}&{}&{\ddots}&{\vdots}\\
{}&{}&{}&{1}\\
\end{pmatrix}
\]
В частности, если $B'$ -- матрица билинейной формы в базисе $e_1',\ldots,e_n'$ и $B_k'$ -- матрица ее ограничения на $U_k$ в базисе $e_1',\ldots,e_k'$, то $B_k' = C_k^* B_k C_k$, где $C_k$ -- верхнетреугольная матрица с единицами на диагонали из формулы выше.
То есть $\det B_k' = \det B_k$.
В частности $B_k'$ всегда будет невырожденная матрица.

Будем искать векторы $e_i'$ по очереди в виде:
\[
e_k' = e_k + \lambda_1 e_1' + \ldots + \lambda_{k-1}e_{k-1}'
\]
Кроме этого, будем показывать, что $\beta(e_k',e_k')\neq 0$.
Последнее равенство позволяет находить их по индукции, положив $e_1' = e_1$.
В этом случае $\beta(e_1',e_1') = \det B_1 \neq 0$.
Пусть мы уже нашли векторы $e_1',\ldots,e_{k-1}'$ (и показали, что $\beta(e_1',e_1')\neq 0,\ldots,\beta(e_{k-1}',e_{k-1}')\neq 0$), давайте предъявим формулу для $e_k'$ и покажем, что $\beta(e_k',e_k')\neq 0$.
У нас должно получиться
\[
e_k' = e_k + \lambda_1 e_1' + \ldots + \lambda_{k-1}e_{k-1}'
\]
Вектор $e_k'$ должен быть ортогонален всем построенным $e_i'$.
Умножим предыдущее равенство относительно $\beta$ на $e_i'$ слева (то есть применим $\beta(e_i',{-})$),%
\footnote{Обратите внимание, что в отличие от случая билинейной формы, тут мы должны умножить слева.
Это нужно, чтобы коэффициенты $\lambda_i$ из полуторалинейной формы вынеслись без комплексного сопряжения.}
получим
\[
0 = \beta(e_i',e_k') = \beta(e_i',e_k) +\sum_{j=1}^{k-1}\lambda_j \beta(e_i', e_j')
= \beta(e_i', e_k) + \lambda_i \beta(e_i', e_i')
\]
Так как по индуктивному предположению все числа $\beta(e_i',e_i') \neq 0$ при $i< k$, то мы получаем формулу
\[
e_k' = e_k - \frac{\beta(e_1', e_k)}{\beta(e_1',e_1')} e_1' - \ldots - \frac{\beta(e_{k-1}', e_k)}{\beta(e_{k-1}',e_{k-1}')} e_{k-1}'
\]
Осталось проверить, что $\beta(e_k', e_k')\neq 0$.
По построению матрица $B_k'$ является диагональной с числами $\beta(e_i',e_i')$ на диагонали.
Как было отмечено выше, в силу особенностей замены $\det B_k' = \det B_k\neq 0$.
С другой стороны $\det B_k'$ равен произведению диагональных элементов, значит они все должны быть ненулевыми.
В частности $\beta(e_k',e_k')$ тоже не ноль.
Кроме того, это рассуждение показывает, что диагональные элементы $B'$ считаются по формулам $\beta(e_i',e_i') = \frac{\Delta_i}{\Delta_{i-1}}$, где $\Delta_i = \det B_i$ и $\Delta_0 = 1$.


\subsection{Критерий Сильвестра для полуторалинейных форм}

Как и в случае вещественных билинейных форм из метода Якоби можно вытащить критерий положительной определенности для эрмитовых форм.
Он называется критерием Сильвестра.

В  начале сделаем одно наблюдение.
Пусть $\beta\colon V\times V\to \mathbb C$ -- некоторая полуторалинейная форма.
И пусть фиксированы два базиса с матрицей перехода: $(e_1',\ldots,e_n') = (e_1,\ldots,e_n)C$.
Обозначим матрицы формы $\beta$ через $B'$ и $B$ в соответствующих базисах.
Тогда мы знаем, что $B' = C^* B C$.
В частности
\[
\det B' = \det C^*\det B \det C = \det\bar C^t \det C\det B = \det \bar C\det C\det B = \overline{\det C}\det C \det B = |\det C|^2 \det B
\]
То есть определитель полуторалинейной формы (не обязательно эрмитовой) определен однозначно с точностью до умножения на положительное вещественное число.
Это означает, что либо определитель ноль, либо у определителя не меняется аргумент (имеется в виду аргумент комплексного числа).
В частности, если определитель $\beta$ является вещественным положительным числом в некотором базисе, то он остается положительным вещественным в любом другом базисе.

\begin{claim}
[Критерий Сильвестра]
Пусть $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма и пусть в некотором базисе $e_1,\ldots,e_n$ она записывается в виде $\beta(x, y) = \bar x^t B y$, где $B\in\operatorname{M}_n (\mathbb C)$ -- самосопряженная матрица, то есть $B^* = B$.
Обозначим ее угловые миноры через $\Delta_1,\ldots,\Delta_n$.
Тогда
\begin{enumerate}
\item Форма $\beta$ положительно определена тогда и только тогда, когда $\Delta_i > 0$ для любого $i$.

\item Форма $\beta$ отрицательно определена тогда и только тогда, когда $\sgn \Delta_i = (-1)^i$ для любого $i$.
\end{enumerate}
\end{claim}
\begin{proof}
(2) выводится из (1) заменой формы $\beta$ на $-\beta$.
При этом $\Delta_i(-\beta) = (-1)^i \Delta_i(\beta)$.
Потому нам достаточно доказать только первый пункт.

(1) $\Rightarrow$ Если форма $\beta$ положительно определена, то ее ограничение $\beta|_{U_k}$, где $U_k = \langle e_1,\ldots,e_k\rangle$, тоже положительно определено.
Тогда в некотором базисе $\beta|_{U_k}$ задается единичной матрицей.
А значит ее определитель положительное число.
Значит и в любом другом базисе ее определитель положительное число, например, в базисе $e_1,\ldots,e_k$.
Но этот определитель равен $\Delta_k$.

(1)$\Leftarrow$ В этом случае выполнены условия для выполнимости метода Якоби, а именно, $\Delta_i\neq 0$.
Значит можно диагонализировать нашу форму с числами $\frac{\Delta_i}{\Delta_{i-1}} > 0$ на диагонали.
\end{proof}

\subsection{Эрмитово векторное пространство}

\begin{definition}
Пусть $V$ -- векторное пространство над $\mathbb C$ и $({-},{-})\colon V\times V\to \mathbb C$ -- полуторалинейная форма.
Форма $({-},{-})$ называется эрмитовым скалярным произведением если
\begin{enumerate}
\item $({-},{-})$ эрмитова.

\item $({-},{-})$ положительна определена.
\end{enumerate}

Пространство $V$ вместе с эрмитовым скалярным произведением называется эрмитовым пространством.%
\footnote{Это прямой аналог евклидова пространства в комплексном мире.}
\end{definition}

Благодаря тому, что мы грамотно определили эрмитовы скалярные произведения, теперь для любого вектора $v\in V$ число $(v,v)$ является вещественным и более того $(v,v) \geqslant 0$, причем равенство достигается только в случае $v=0$.
А значит можно вводить все те же самые геометрические понятия, что мы вводили в евклидовом случае.
Этим безобразием мы сейчас и займемся.
Главная неприятная особенность эрмитовых пространств -- тут не работает сведение к школьной геометрии.
Однако работает сведение к эрмитовым пространствам малой размерности.
Да, они уже не из знакомого со школы геометрического мира, но все же это лучше, чем работать в произвольной размерности.

\begin{definition}
Пусть $V$ -- эрмитово пространство.
Тогда базис $e_1,\ldots,e_n$ называется ортогональным, если  $(e_i, e_j) = 0$ для всех $i\neq j$.
Он называется ортонормированным, если он ортогональный и $(e_i, e_i) = 1$.
\end{definition}

\begin{definition}
Пусть $V, ({-},{-})_V$ и $U, ({-},{-})_U$ -- два эрмитовых пространства.
Тогда отображение $\phi\colon V\to U$ называется изоморфизмом эрмитовых пространств, если $\phi$ -- изоморфизм векторных пространств, сохраняющий скалярное произведение, то есть $(\phi(v), \phi(u))_U = (v, u)_V$ для всех $v, u \in V$.
В этом случае эрмитовы пространства называются изоморфными.
\end{definition}

Как и в случае евклидовых пространств верно следующее утверждение.

\begin{claim}
Два эрмитовых пространства $V, ({-},{-})_V$ и $U, ({-},{-})_U$  изоморфны тогда и только тогда, когда они имеют одинаковую размерность.
\end{claim}
\begin{proof}
Мы должны слово в слово повторить доказательство утверждения~\ref{claim::EuclideanIsom}.
Если два эрмитовых пространства изоморфны, то их подлежащие пространства $V$ и $U$ изоморфны как векторные пространства, а значит имеют одинаковую размерность.
В обратную сторону.
Выберем в пространстве $V$ ортонормированный базис $e_1,\ldots,e_n$ и в пространстве $U$ ортонормированный базис $f_1,\ldots, f_n$.
Они существуют, потому что для любой положительно определенной эрмитовой формы можно выбрать базис, в котором его матрица единичная.
Тогда ясно, что линейное отображение отправляющее $e_i$ в $f_i$ удовлетворяет нужным свойствам.
\end{proof}

Еще одно замечание.
Как и в случае евклидовых пространств.
Формулы из метода Якоби в эрмитовом пространстве задают процесс называемый ортогонализацией Грама-Шмидта.


\begin{definition}
Пусть $V$ -- эрмитово векторное пространство и $v\in V$ определим длину вектора $v$ по формуле $|v| = \sqrt{(v,v)}$.
\end{definition}

\begin{claim}
[Неравенство Коши-Буняковского]
Пусть $V$ -- эрмитово пространство и $v,u\in V$ -- произвольные векторы.
Тогда $|(v,u)|\leqslant |v| |u|$, причем равенство достигается тогда и только тогда, когда векторы $v$ и $u$ лежат на одной прямой.
\end{claim}
\begin{proof}
Доказательство один в один повторяет вещественный случай.
Если хотя бы один из векторов нулевой, то неравенство превращается в верное равенство и в этом случае $v$ и $u$ лежат на одной прямой.
Потому достаточно считать, что оба вектора не нулевые.
Тогда выберем $e_1$ -- единичный вектор на прямой $\langle v\rangle$, а вектор $e_2$ выберем в плоскости $\langle v, u \rangle$ длины один и ортогональным к $e_1$ (воспользуемся методом ортогонализации Грама-Шмидта).
Тогда можно считать, что $v,u\in \mathbb C^2$ и скалярное произведение является стандартным, то есть задается $(x, y) = \bar x^t y$.
В силу выбора базиса мы знаем, что 
\[
v=
\begin{pmatrix}
{a}\\{0}
\end{pmatrix}
\quad \text{и} \quad
u =
\begin{pmatrix}
{b}\\{c}
\end{pmatrix}
\]
Тогда $|(v,u)| = |ab|$ и $|v||u| = |a|\sqrt{|b|^2 + |c^2|}$.
Доказываемое неравенство принимает вид $|ab|\leqslant |a|\sqrt{|b|^2+|c|^2}$, что очевидно.

Теперь надо понять, когда в этом неравенстве достигается равенство.
Причем мы считаем, что $a\neq 0 $ (так как оба вектора ненулевые).
В этом случае равенство $|b| = \sqrt{|b|^2+|c|^2}$ достигается тогда и только тогда, когда $c = 0$.
То есть равенство достигается тогда и только тогда, когда $ v$ и $u$ лежат на одной прямой.
\end{proof}

\paragraph{Замечания про углы}

% TO DO
% Переписать про углы!
Давайте в начале посмотрим на ситуацию в евклидовом пространстве.
Пусть у нас есть два вектора $v, u\in V$ как на картинке ниже.
\[
\xymatrix@R=10pt{
	{}&{}&{}&{}&{}\\
	{}&{}&{}\ar[rr]_v\ar@{--}[ll]\ar[rru]^u&{}&{}\\
	{}&{}&{}&{}&{}\\
}
\quad
\quad
\quad
\xymatrix@R=10pt{
	{}&{}&{}&{}&{}\\
	{}&{}&{}\ar[rr]_v\ar@{--}[ll]\ar[lld]^{-u}&{}&{}\\
	{}&{}&{}&{}&{}\\
}
\]
Тогда мы можем посмотреть на угол между прямыми $\langle v\rangle$ и $\langle u\rangle$.
Это по определению меньший угол из двух на картинках, он измеряется в диапазоне $[0, \pi / 2]$ и его можно найти по формуле $\cos\alpha = \frac{|(v, u)|}{|v| |u|}$.
Однако ситуации на картинках отличаются так: слева косинус положительный, а справа отрицательный.
То есть у $\cos\alpha$ есть знак, этот знак не чувствует угол между прямыми, но отвечает в некотором смысле за ориентацию векторов по отношению к тому углу, который мы замерили.
А так как вещественная прямая является линейно упорядоченным множеством, то на нем есть всего два направления, которые и соответствуют знакам плюс и минус у скалярного произведения $(v, u)$.
На этот знак еще можно смотреть так, мы берем ортогональную проекцию $u$ на $\langle v\rangle$ и проверяем сонаправлены векторы или нет.

Если мы возьмем на вооружение эту точку зрения, то ее можно распространить на комплексный случай.
То есть мы будем мерить угол между двумя прямыми натянутыми на вектор, а потом замерять расхождение между направлениями одного вектора и ортогональной проекции другого вектора на первую прямую.
Тут еще важно понимать, что из-за несимметричности эрмитова произведения в полном смысле $(v, u) = \overline{(u, v)}$ тут важен порядок!
Мы проектируем именно второй вектор на первую прямую.
Угол начинает зависеть от порядка векторов.

В итоге мы приходим к таким рассуждениям.
Из неравенства Коши-Буняковского следует, что для любых двух векторов $v,u\in V$ верно $-1\leqslant \frac{|(v,u)|}{|v| |u|}\leqslant 1$.
А значит найдется единственное число $\alpha\in [0,\pi/2]$ такое, что $\cos \alpha = \frac{|(v,u)|}{|v| |u|}$.
Это число называется углом между прямыми $\langle v\rangle$ и $\langle u \rangle$ и не зависит от порядка векторов.
Кроме того, выражение $\frac{(v, u)}{|v| |u|}$ можно представить в тригонометрической форме $r e^{i\varphi}$, где $r = \cos \alpha$ -- модуль, а $\varphi \in [0,2\pi)$ -- аргумент.
Выражение $e^{i\varphi}$ -- это поляризационный фактор, который измеряет отклонение от сонаправленности упорядоченной пары векторов $v, u$.
Он аналогичен знаку $\pm$ из вещественного случая, но так как комплексная прямая не упорядочена, то на ней есть много разных причин быть не сонаправленными.
Все отклонения задаются аргументом скалярного произведения.

\begin{definition}
Пусть $V$ -- эрмитово пространство и $v,u\in V$ -- два вектора.
Тогда найдутся такие числа $\alpha\in[0,\pi/2]$ и $\varphi\in [0, 2\pi)$ такие, что $\cos \alpha\cdot e^{i\varphi} = \frac{(v,u)}{|v| |u|}$.
Тогда $\alpha$ называется углом между прямыми $\langle v\rangle$ и $\langle u\rangle$ и обозначается $\angle(v, u)$, а $e^{i\varphi}$ -- это поляризационный множитель, а $\varphi$ -- поляризационный угол.
\end{definition}

\begin{remark}
\begin{itemize}
\item
Обратите внимание, что поляризационный множитель зависит от порядка векторов.
Действительно, если $\frac{(v, u)}{|v| |u|} = \cos \alpha \cdot e^{i\varphi}$, то 
\[
\frac{(u, v)}{|v| |u|} = \frac{\overline{(u, v)}}{|v| |u|} = \cos \alpha\cdot e^{-i\varphi}
\]
Таким образом поляризационный угол $\varphi$ сменит знак на противоположный.
Эта ситуация аналогична ориентированному объему, который зависит от порядка, в котором рассматриваются векторы в параллелепипеде.

\item
Если записывать скалярное произведение через угол между прямыми и поляризацию, то в евклидовом случае получается формула
\[
(v, u) = |v| |u| \cos \alpha \sgn
\]
где $\sgn$ обозначает знак $\pm 1$ в зависимости от положения векторов.
А в эрмитовом случае получается формула
\[
(v, u) = |v| |u| \cos \alpha\cdot  e^{i\varphi}
\]
где $\varphi$ -- поляризационный угол.
В этом смысле эрмитов случай расширяет евклидов, в котором возможны только два угла $0$ и $\pi$.
\end{itemize}
\end{remark}

\begin{definition}
Матрица $C\in \operatorname{M}_n(\mathbb C)$ называется унитарной, если $C^* C = E$.
\end{definition}

Эквивалентные определения унитарности: $CC^* = E$ или $C^* = C^{-1}$.

\begin{claim}
Пусть $V$ -- эрмитово пространство и $e_1,\ldots,e_n$ -- ортонормированный базис.
Тогда
\begin{enumerate}
\item Для любой унитарной матрицы $C\in \operatorname{M}_n(\mathbb C)$ векторы $(e_1,\ldots,e_n)C$ являются ортонормированным базисом.

\item Если $f_1,\ldots,f_n$ -- любой другой ортонормированный базис, то матрица перехода $C$, то есть $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$, является унитарной.
\end{enumerate}
\end{claim}
\begin{proof}
Доказательство полностью аналогично доказательству евклидового случая (утверждение~\ref{claim::OrthoBasisDiscrEucl}) и потому оставляется в качестве упражнения.
\end{proof}


\subsection{Обзор геометрических понятий в эрмитовом пространстве}

\paragraph{Ортогональные проекции}

Если $V$ -- эрмитово пространство и $U\subseteq V$ -- некоторое подпространство, то $V = U\oplus U^\bot$.
Это значит, что любой вектор раскладывается единственным образом в виде $v = \pr_U v + \ort_U v$, где $\pr_U v\in U$ и $\ort_U v \in U^\bot$.
Как и в евклидовом случае их называют проекцией и ортогональным дополнением вектора $v$.

\paragraph{Углы и расстояния}

Как и в случае вещественного пространства определяется расстояние между векторами $\rho(v,u) = |v - u|$, где $v,u\in V$.
И расстояние между множествами $\rho(X, Y) = \inf_{x\in X, y\in Y}\rho(x,y)$, где $X,Y\subseteq V$.
С углами приходится говорить лишь про углы между прямыми, а не векторами из-за поляризационного множителя их нельзя сравнивать между собой.
Потому угол между вектором и подпространством определяется так $\angle(v,L) = \inf_{u\in L}\angle(v,u)$.
Я оставлю в качестве упражнения показать, следующее.

\begin{claim}
\label{claim::DistAngleHerm}
Пусть $V$ -- эрмитово пространство, $L\subseteq V$ -- подпространство, $v\in V$ -- некоторый вектор.
Тогда
\begin{enumerate}
\item $\rho(v, L) = |\ort_L v|$.

\item $\angle(v, L) = \angle(v, \pr_L v)$.%
\footnote{Если $\pr_L v = 0$, то надо считать косинус угла нулевым, то есть угол равным $\pi/2$.}
\end{enumerate}
\end{claim}


\paragraph{Метод наименьших квадратов}

Хочу отметить, что в эрмитовом пространстве так же можно применять метод наименьших квадратов.
То есть метод для решения систем вида $Ax = b$, где $A\in \operatorname{M}_{m\,n}(\mathbb C)$, $b\in \mathbb C^m$ и $x\in\mathbb C^n$ -- столбец неизвестных, в случае, когда данная система не имеет решения.
В этом случае надо минимизировать $\rho(Ax, b)$ по $x$.
Если минимум достигается на $x_0$, то $b_0 = Ax_0$ является ортогональной проекцией $b$ на пространство $\langle A \rangle$.
Если столбцы матрицы $A$ линейно независимы, то явные формулы для $x_0$ и $b_0$ следующие: $b_0 = A(A^*A)^{-1}A^*b$ и $x_0 = (A^*A)^{-1}A^*b$.
Это аналог формулы <<Атата>>.%
\footnote{Так как транспонирование в эрмитовом пространстве заменяется звездочкой, то может быть имеет смысл называть эту формулу <<Азаза>>?..}

\paragraph{Матрица Грама и формальный объем}

Пусть $V$ -- эрмитово пространство.
Если $v_1,\ldots,v_k\in V$, то матрица $G(v_1,\ldots,v_k)$ с элементами $(v_i, v_j)$ называется матрицей Грама.
Эта матрица самосопряжена в смысле $G(v_1,\ldots,v_k)^* = G(v_1,\ldots,v_k)$.
При этом $\det G(v_1,\ldots,v_k)\geqslant 0$ причем равенство достигается тогда и только тогда, когда $v_1,\ldots,v_k$ линейно зависимы.

Сказать, что такое параллелепипед в комплексном пространстве сложно, потому объем определяется формально для набора векторов $v_1,\ldots,v_k\in V$.
А именно
\[
\Vol_k(v_1,\ldots,v_k) = \sqrt{\det G(v_1,\ldots,v_k)}
\]
Для данного объема также выполняется формула через площадь основания на высоту:
\[
\Vol_k(v_1,\ldots,v_k) = \Vol_{k-1}(v_1,\ldots,v_{k-1}) \rho(v_k, \langle v_1,\ldots,v_{k-1}\rangle)
\]
Можно определить поляризованный объем, пользуясь определителем.
Делается это аналогично вещественному случаю, с той лишь разницей, что базисы будут отличаться  не знаком, а комплексным аргументом и у нас получается много поляризаций (а не ориентаций) для базисов.
Я не буду здесь вдаваться в подробности.

\subsection{Комплексификация}


Задача этого параграфа следующая, мы хотим построить процедуру, которая преобразует вещественные векторные пространства в комплексные и одновременно с этим операторы и билинейные формы превращает в операторы и полуторалинейные формы.
Эта процедура и будет называться комплексификаций.
На самом деле мы уже знаем на примитивном уровне, как проводить такую процедуру, как показывает пример ниже.
Однако, его недостаток в том, что эта конструкция зависит от базиса, а значит, мы не можем ничего гарантировать в другом базисе.
Куда удобнее было бы задать эту процедуру абстрактно, а потом проверить, что в базисе она задается по правилам из примера.
Этому и будет посвящен этот раздел.%
\footnote{На самом деле есть еще процедура овещестления, но она тривиальна, а потому является верхом формализма.
По простому, каждое векторное пространство над $\mathbb C$ можно рассматривать как векторное пространство над $\mathbb R$, просто забыва про то, что мы умели умножать на мнимую единицу.
Может быть имеет смысл помучить вас этим материалом, но я уже оторвался на тензорах и сейчас на это нет времени и возможности.}

\paragraph{VIP пример}

Пусть $V = \mathbb R^n$ -- наше векторное пространство, оператор $\varphi \colon \mathbb R^n\to \mathbb R^n$ задан по правилу $x \mapsto Ax$, где $A\in \Matrix{n}$, и есть билинейная форма $\beta \colon \mathbb R^n\times \mathbb R^n\to \mathbb R$ задана $\beta(x,y) = x^t By$, где $B\in \Matrix{n}$.
Тогда мы можем заменить $V$ на пространство $V_{\mathbb C} = \mathbb C^n$, оператор $\varphi$ на $\varphi_{\mathbb C}\colon \mathbb C^n \to \mathbb C^n$ по правилу $z\mapsto Az$, и билинейную форму $\beta$ на полуторалинейную форму $\beta_{\mathbb C}\colon \mathbb C^n \times \mathbb C^n \to \mathbb C$ по правилу $\beta_{\mathbb C}(z, w)= \bar z^t B w$.
Вот и все.
Ничего страшного.
Кроме этого, мы естественным образом получаем вложение $\mathbb R^n$ в $\mathbb C^n$.
Теперь наша задача -- научиться все это хозяйство проделывать без явного выбора базиса и координат.

\begin{definition}
Пусть $V$ -- вещественное векторное пространство, определим комплексное векторное пространство $V_{\mathbb C}$ следующим образом:
\begin{itemize}
\item Как множество $V_{\mathbb C} = \{v + i u \mid v,u\in V\}$.
То есть $V_\mathbb C$ -- это множество картинок вида $v+iu$, где $i$ -- значок для мнимой единицы, а $v$ и $u$ -- векторы из $V$.
Формально $V_\mathbb C = V\times V$, то есть каждая картинка $v+iu$ -- это просто пара векторов $(v,u)\in V^2$.

\item Операция сложения задана правилом
\[
(v_1+iu_1) + (v_2 + iu_2) = (v_1+v_2) + i(u_1+u_2),\quad v_1,v_2,u_1,u_2\in V
\]

\item Умножения на скаляр задано по правилу
\[
(\lambda + i\mu) (v+iu) = (\lambda v - \mu u) + i(\lambda u + \mu v),\quad \lambda,\mu \in \mathbb R, \;\; v,u\in V
\]
\end{itemize}
Пространство $V_\mathbb C$ называется комплексификацией пространства $V$.
\end{definition}

Можно проверить, что таким образом заданные операции на $V_\mathbb C$ превращают его в векторное пространство над $\mathbb C$.%
\footnote{Я знаю, что вы мне тут поверите на слово.
Но я настоятельно рекомендую проделать эту проверку.}

\paragraph{Замечания}

\begin{itemize}
\item Обратите внимание на то, что конструкция комплексификации повторяет конструкцию комплексных чисел.

\item Если взять $V = \mathbb R$, то $V_\mathbb C$ -- это в точности конструкция для комплексных чисел, то есть $V_\mathbb C = \mathbb C$.
В более общем случае, если $V = \mathbb R^n$, то $V_\mathbb C = \mathbb C^n$.

\item Если $v+iu\in V_\mathbb C$, где $v,u\in V$, то $v + iu = 0$ в $V_\mathbb C$ тогда и только тогда, когда $v = u = 0 $ в $V$.

\end{itemize}

\begin{definition}
Пусть $V$ -- вещественное векторное пространство и $V_\mathbb C$ -- его комплексификация.
Если $w = v +i u\in V_\mathbb C$, то вектор $v\in V$ называется вещественной частью $w$ и обозначается $\Re w$, а вектор $u\in V$ называется мнимой частью $w$ и обозначается $\Im w$.
Отображение $V_\mathbb C\to V_\mathbb C$ по правилу $v+iu\mapsto v-iu$ называется сопряжением и является $\mathbb R$ линейным отображением.
\end{definition}

Обратите внимание, что мы можем считать, что $V\subseteq V_\mathbb C$, отождествляя каждый вектор $v\in V$ с вектором $v+i0\in V_\mathbb C$.
Это ровно тот способ, каким мы вкладываем вещественные числа в комплексные, но для векторных пространств.

\begin{claim}
\label{claim::ComplfixBasis}
Пусть $V$ -- вещественное векторное пространство и $e_1,\ldots,e_n\in V$ -- базис.
Тогда векторы $e_1,\ldots,e_n$ являются базисом $V_\mathbb C$, то есть $\dim_\mathbb R V = \dim_\mathbb C V_\mathbb C$.
\end{claim}
\begin{proof}
Нам надо проверить, что векторы $e_1,\ldots,e_n$ линейно независимы и все порождают.

Линейная независимость.
Предположим найдутся $z_1,\ldots,z_n\in \mathbb C$ такие, что $z_1 e_1+ \ldots+ z_n e_n = 0$ в $V_\mathbb C$.
Пусть $z_k = a_k + i b_k$, где $a_k,b_k \in \mathbb R$.
Тогда соотношение линейной зависимости можно переписать так:
\begin{gather*}
(a_1+ib_1)e_1 + \ldots + (a_n + i b_n)e_n = 0\\
(a_1 e_1 + \ldots + a_n e_n) + i(b_1 e_1 + \ldots + b_n e_n) = 0\;\text{в}\; V_\mathbb C
\end{gather*}
Последнее означает, что и мнимая и вещественная части равны нулю, то есть
\[
a_1 e_1 + \ldots + a_n e_n = 0\quad \text{и}\quad b_1 e_1 + \ldots + b_n e_n = 0\;\text{в}\; V
\]
Так как $e_i$ -- базис, это значит, что все $a_i$ и $b_i$ равны нулю, а значит и все $z_i$ равны нулю, что и требовалось.

Порождаемость.
Пусть $v + i u\in V_\mathbb C$ -- произвольный вектор.
Тогда $v = a_1e_1+\ldots + a_n e_n$ и $u = b_1 e_1 + \ldots + b_n e_n$, так как $e_i$ -- базис.
Тогда положим $z_k = a_k + i b_k$, получим, что $v + iu = z_1 e_1 + \ldots + z_n e_n$.
\end{proof}

\subsection{Комплексификация линейных отображений и билинейных форм}
\label{subsection::complexification}

\begin{definition}
Пусть $\phi\colon V\to U$ -- линейное отображение между вещественными векторными пространствами.
Определим отображение $\phi_\mathbb C\colon V_\mathbb C\to U_\mathbb C$ по правилу $v+iu \mapsto \phi(v) + i\phi(u)$.
Полученное отображение является $\mathbb C$ линейным отображением и называется комплексификацией линейного отображения $\phi$.
\end{definition}

\paragraph{Замечание}

Пусть $\phi\colon V\to U$ -- линейное  отображение между вещественными векторными пространствами.
Пусть $e_1,\ldots,e_n$ -- базис в $V$ и $f_1,\ldots,f_m$ -- базис в $U$ и пусть $A\in \MatrixDim{m}{n}$ -- матрица отображения $\phi$ в указанной паре базисов.
По определению это означает, что $\phi(e_1,\ldots,e_n) = (f_1,\ldots,f_m)A$.
Теперь рассмотрим отображение $\phi_\mathbb C \colon V_\mathbb C\to U_\mathbb C$.
Так как множества векторов $e_1,\ldots,e_n$ и $f_1,\ldots,f_m$ являются базисами пространств $V_\mathbb C$ и $U_\mathbb C$ соответственно (утверждение~\ref{claim::ComplfixBasis}), то равенство $\phi(e_1,\ldots,e_n) = (f_1,\ldots,f_m)A$ означает, что $A$ является матрицей отображения $\phi_\mathbb C$ в этих базисах.
По сути это значит, что если в координатах $\phi$ задавалось в виде $\mathbb R^n \to \mathbb R^n$ по правилу $x \mapsto Ax$, то $\phi_\mathbb C$ задается в координатах в виде $\mathbb C^n \to \mathbb C^n$ по правилу $z\mapsto Az$, ровно то, что обещалось в примере.
Кроме того, философия этого явления следующая.
Если свойства отображения зависят только от матрицы, то эти свойства сохраняются при переходе к комплексификации.


\begin{definition}
\label{definition::ComplfixBil}
Пусть $\beta\colon V\times V\to \mathbb R$ -- билинейная форма на вещественном векторном пространстве $V$.
Определим билинейную форму $\beta_\mathbb C \colon V_\mathbb C\times V_\mathbb C\to \mathbb C$ по следующему правилу
\[
\beta_\mathbb C(v_1+iu_1, v_2 + iu_2) = \beta(v_1, v_2) + i\beta(v_1,u_2) - i\beta(u_1, v_2) + \beta(u_1, u_2)
\]
Тогда полученное отображение $\beta_\mathbb C$ будет полуторалинейным и называется комплексификацией формы $\beta$.%
\footnote{Опять же, настоятельно рекомендую проверить полуторалинейность полученной формы, не пожалеете.}
\end{definition}

\paragraph{Замечание}

Пусть $\beta\colon V\times V\to \mathbb R$ -- билинейная форма на вещественном векторном пространстве и пусть $e_1,\ldots,e_n$ -- базис $V$.
Пусть $B\in \Matrix{n}$ -- матрица билинейной формы в этом базисе, то есть $b_{ij} = \beta(e_i,e_j)$.
Рассмотрим комплексификацию формы $\beta_\mathbb C \colon V_\mathbb C\times V_\mathbb C\to \mathbb C$.
Так как $e_1,\ldots,e_n$ -- базис $V_\mathbb C$ (утверждение~\ref{claim::ComplfixBasis}), то матрица $B$ будет матрицей полуторалинейной формы $\beta_\mathbb C$ в этом базисе.
По сути это значит, что если в координатах $\beta$ задавалась в виде $\beta(x, y) = x^t B y$, то $\beta_\mathbb C$ в координатах превращается в $\beta_\mathbb C(z, w) = \bar z^t B w$.
Философия этого явления такая же, как и у линейных отображений.
Если какое-то свойство билинейной формы зависит только от матрицы, то оно остается верным и при переходе к комплексификации.
